{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation.\n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# DIY smart security camera PoC using Raspberry Pi Camera and\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import numpy\n",
    "import select\n",
    "import ntpath\n",
    "import argparse\n",
    "import picamera\n",
    "import picamera.array\n",
    "\n",
    "import mvnc.mvncapi as mvnc\n",
    "\n",
    "from PIL import Image\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import PIL.ImageFont\n",
    "\n",
    "from time import localtime, strftime\n",
    "\n",
    "# \"Class of interest\" - Display detections only if they match this class ID\n",
    "CLASS_PERSON = 15\n",
    "\n",
    "# Detection threshold: Minimum confidance to tag as valid detection\n",
    "CONFIDANCE_THRESHOLD = 0.60  # 60% confidant\n",
    "\n",
    "# Variable to store commandline arguments\n",
    "ARGS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation. \n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# Utilities to help deserialize the output list from\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS) \n",
    "\n",
    "# ---- Deserialize the output from an SSD based network ----\n",
    "# @param output The NCS returns a list/array in this structure:\n",
    "# First float16: Number of detections\n",
    "# Next 6 values: Unused\n",
    "# Next consecutive batch of 7 values: Detection values\n",
    "#   0: Image ID (always 0)\n",
    "#   1: Class ID (index into labels.txt)\n",
    "#   2: Detection score\n",
    "#   3: Box left coordinate (x1) - scaled value between 0 & 1\n",
    "#   4: Box top coordinate (y1) - scaled value between 0 & 1\n",
    "#   5: Box right coordinate (x2) - scaled value between 0 & 1\n",
    "#   6: Box bottom coordinate (y2) - scaled value between 0 & 1\n",
    "#\n",
    "# @return output_dict A Python dictionary with the following keys:\n",
    "# output_dict['num_detections'] = Total number of valid detections\n",
    "# output_dict['detection_classes_<X>'] = Class ID of the detected object\n",
    "# output_dict['detection_scores_<X>'] = Percetage of the confidance\n",
    "# output_dict['detection_boxes_<X>'] = A list of 2 tuples [(x1, y1) (x2, y2)]\n",
    "# Where <X> is a zero-index count of num_detections\n",
    "\n",
    "\n",
    "def ssd(output, confidance_threshold, shape):\n",
    "\n",
    "    # Dictionary where the deserialized output will be stored\n",
    "    output_dict = {}\n",
    "\n",
    "    # Extract the original image's shape\n",
    "    height, width, channel = shape\n",
    "\n",
    "    # Total number of detections\n",
    "    output_dict['num_detections'] = int(output[0])\n",
    "\n",
    "    # Variable to track number of valid detections\n",
    "    valid_detections = 0\n",
    "\n",
    "    for detection in range(output_dict['num_detections']):\n",
    "\n",
    "        # Skip the first 7 values, and point to the next batch of 7 values\n",
    "        base_index = 7 + (7 * detection)\n",
    "\n",
    "        # Record only those detections whose confidance meets our threshold\n",
    "        if(output[base_index + 2] > confidance_threshold):\n",
    "\n",
    "            output_dict['detection_classes_' + str(valid_detections)] = \\\n",
    "                int(output[base_index + 1])\n",
    "\n",
    "            output_dict['detection_scores_' + str(valid_detections)] = \\\n",
    "                int(output[base_index + 2] * 100)\n",
    "\n",
    "            x = [int(output[base_index + 3] * width),\n",
    "                 int(output[base_index + 5] * width)]\n",
    "\n",
    "            y = [int(output[base_index + 4] * height),\n",
    "                 int(output[base_index + 6] * height)]\n",
    "\n",
    "            output_dict['detection_boxes_' + str(valid_detections)] = \\\n",
    "                list(zip(y, x))\n",
    "\n",
    "            valid_detections += 1\n",
    "\n",
    "    # Update total number of detections to valid detections\n",
    "    output_dict['num_detections'] = int(valid_detections)\n",
    "\n",
    "    return(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation. \n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# Utilities to help visualize the output from\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "\n",
    "def draw_bounding_box( y1, x1, y2, x2, \n",
    "                       img, \n",
    "                       thickness=4, \n",
    "                       color=(255, 255, 0),\n",
    "                       display_str=() ):\n",
    "\n",
    "    \"\"\" Inputs\n",
    "    (x1, y1)  = Top left corner of the bounding box\n",
    "    (x2, y2)  = Bottom right corner of the bounding box\n",
    "    img       = Image/frame represented as numpy array\n",
    "    thickness = Thickness of the bounding box's outline\n",
    "    color     = Color of the bounding box's outline\n",
    "    \"\"\"\n",
    "\n",
    "    img = PIL.Image.fromarray( img )\n",
    "    draw = PIL.ImageDraw.Draw( img )\n",
    "\n",
    "    for x in range( 0, thickness ):\n",
    "        draw.rectangle( [(x1-x, y1-x), (x2-x, y2-x)], outline=color )\n",
    "\n",
    "    font = PIL.ImageFont.load_default()\n",
    "    draw.text( (x1, y1), display_str, font=font )\n",
    "\n",
    "    return numpy.array( img )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Open the enumerated device and get a handle to it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ncs_device():\n",
    "\n",
    "    # Look for enumerated NCS device(s); quit program if none found.\n",
    "    devices = mvnc.EnumerateDevices()\n",
    "    if len(devices) == 0:\n",
    "        print('No devices found')\n",
    "        quit()\n",
    "\n",
    "    # Get a handle to the first enumerated device and open it\n",
    "    device = mvnc.Device(devices[0])\n",
    "    device.OpenDevice()\n",
    "\n",
    "    return device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Load a graph file onto the NCS device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_graph(device, graph_name):\n",
    "\n",
    "    # Read the graph file into a buffer\n",
    "    with open(graph_name, mode='rb') as f:\n",
    "        blob = f.read()\n",
    "\n",
    "    # Load the graph buffer into the NCS\n",
    "    graph = device.AllocateGraph(blob)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Pre-process the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(frame, dim, mean, scale):\n",
    "\n",
    "    # Read & resize image\n",
    "    # [Image size is defined by choosen network, during training]\n",
    "    img = Image.fromarray(frame)\n",
    "    img = img.resize(dim)\n",
    "    img = numpy.array(img)\n",
    "\n",
    "    # Mean subtraction & scaling [A common technique used to center the data]\n",
    "    img = img.astype(numpy.float16)\n",
    "    img = (img - numpy.float16(mean)) * scale\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Read & print inference results from the NCS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_image(graph, img, frame):\n",
    "\n",
    "    # Load the image as a half-precision floating point array\n",
    "    graph.LoadTensor(img, 'user object')\n",
    "\n",
    "    # Get the results from NCS\n",
    "    output, userobj = graph.GetResult()\n",
    "\n",
    "    # Get execution time\n",
    "    inference_time = graph.GetGraphOption(mvnc.GraphOption.TIME_TAKEN)\n",
    "\n",
    "    # Deserialize the output into a python dictionary\n",
    "    output_dict = deserialize_output.ssd(\n",
    "                      output,\n",
    "                      CONFIDANCE_THRESHOLD,\n",
    "                      frame.shape)\n",
    "\n",
    "    # Print the results (each image/frame may have multiple objects)\n",
    "    for i in range(0, output_dict['num_detections']):\n",
    "\n",
    "        # Filter a specific class/category\n",
    "        if(output_dict.get('detection_classes_' + str(i)) == CLASS_PERSON):\n",
    "\n",
    "            cur_time = strftime('%Y_%m_%d_%H_%M_%S', localtime())\n",
    "            print('Person detected on ' + cur_time)\n",
    "\n",
    "            # Extract top-left & bottom-right coordinates of detected objects\n",
    "            (y1, x1) = output_dict.get('detection_boxes_' + str(i))[0]\n",
    "            (y2, x2) = output_dict.get('detection_boxes_' + str(i))[1]\n",
    "\n",
    "            # Prep string to overlay on the image\n",
    "            display_str = (\n",
    "                labels[output_dict.get('detection_classes_' + str(i))]\n",
    "                + ': '\n",
    "                + str(output_dict.get('detection_scores_' + str(i)))\n",
    "                + '%')\n",
    "\n",
    "            # Overlay bounding boxes, detection class and scores\n",
    "            frame = visualize_output.draw_bounding_box( \n",
    "                        y1, x1, y2, x2,\n",
    "                        frame,\n",
    "                        thickness=4,\n",
    "                        color=(255, 255, 0),\n",
    "                        display_str=display_str)\n",
    "\n",
    "            # Capture snapshots\n",
    "            img = Image.fromarray(frame)\n",
    "            photo = (os.path.dirname(os.path.realpath(__file__))\n",
    "                     + \"/captures/photo_\"\n",
    "                     + cur_time + \".jpg\")\n",
    "            img.save(photo)\n",
    "\n",
    "    # If a display is available, show image on which inference was performed\n",
    "    if 'DISPLAY' in os.environ:\n",
    "        img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class image_classifier():\n",
    "    def __init__(self,\n",
    "                 graph_name='graph',\n",
    "                 label_names='labels.txt'\n",
    "                 mean=[127.5, 127.5, 127.5],\n",
    "                 scale=0.00789,\n",
    "                 dim=[300, 300],\n",
    "                 colourmode='bgr'):\n",
    "        self.mean = mean\n",
    "        self.scale = scale\n",
    "        self.dim = dim\n",
    "        self.colourmode = colourmode\n",
    "\n",
    "        self.device = open_ncs_device()\n",
    "        self.graph = load_graph(device, graph_name)\n",
    "        \n",
    "            # Load the labels file\n",
    "        labels = [line.rstrip('\\n') for line in\n",
    "                  open(label_names) if line != 'classes\\n']\n",
    "    \n",
    "    def take_picture(self):\n",
    "        with picamera.PiCamera() as camera:\n",
    "            with picamera.array.PiRGBArray(camera) as self.frame:\n",
    "                camera.resolution = (640, 480)\n",
    "                camera.capture(frame, self.colourmode, use_video_port=True)\n",
    "                self.frame = frame\n",
    "                return frame\n",
    "    \n",
    "    def infer_image(self):\n",
    "        img = pre_process_image(self.frame.array)\n",
    "        infer_image(self.graph, img, self.frame.array)\n",
    "    \n",
    "    def close_ncs_device(self):\n",
    "        self.graph.DeallocateGraph()\n",
    "        self.device.CloseDevice()\n",
    "    \n",
    "    \n",
    "    \n",
    "# ---- Define 'main' function as the entry point for this script -------------\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser.add_argument('-g', '--graph', type=str,\n",
    "                        default='../../caffe/SSD_MobileNet/graph',\n",
    "                        help=\"Absolute path to the neural network graph file.\")\n",
    "\n",
    "    parser.add_argument('-l', '--labels', type=str,\n",
    "                        default='../../caffe/SSD_MobileNet/labels.txt',\n",
    "                        help=\"Absolute path to labels file.\")\n",
    "# ==== End of file ===========================================================\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
