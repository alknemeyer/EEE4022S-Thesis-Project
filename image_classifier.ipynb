{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classifier\n",
    "\n",
    "Contains code for the `ImageClassifer` class\n",
    "\n",
    "Much of the code comes from the Movidius GitHub repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'picamera'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a2590a9e790f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;31m#import select\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m#import ntpath\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpicamera\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpicamera\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmvnc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmvncapi\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmvnc\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'picamera'"
     ]
    }
   ],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation.\n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# DIY smart security camera PoC using Raspberry Pi Camera and\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "\n",
    "import os\n",
    "#import sys\n",
    "import numpy as np\n",
    "#import select\n",
    "#import ntpath\n",
    "import picamera\n",
    "import picamera.array\n",
    "import mvnc.mvncapi as mvnc\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import PIL.ImageFont\n",
    "\n",
    "from time import localtime, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the NCS device and load the graph file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ncs_device():\n",
    "\n",
    "    # Look for enumerated NCS device(s); quit program if none found.\n",
    "    devices = mvnc.EnumerateDevices()\n",
    "    if len(devices) == 0:\n",
    "        print('No NCS devices found')\n",
    "        quit()\n",
    "\n",
    "    # Get a handle to the first enumerated device and open it\n",
    "    device = mvnc.Device(devices[0])\n",
    "    device.OpenDevice()\n",
    "\n",
    "    return device\n",
    "\n",
    "def load_graph(device, graph_file_name):\n",
    "    # Read the graph file into a buffer\n",
    "    with open(graph_file_name, mode='rb') as f:\n",
    "        blob = f.read()\n",
    "\n",
    "    # Load the graph buffer into the NCS\n",
    "    graph = device.AllocateGraph(blob)\n",
    "\n",
    "    return graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the image (resizing, scaling, and mean subtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(frame, dim, mean, scale):\n",
    "    # Read & resize image\n",
    "    # [Image size is defined by choosen network, during training]\n",
    "    img = PIL.Image.fromarray(frame).resize(dim)\n",
    "    img = np.array(img, dtype=np.float16)\n",
    "\n",
    "    # Mean subtraction & scaling [A common technique used to center the data]\n",
    "    img = (img - np.float16(mean)) * np.float16(scale)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the inference result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_result(graph, shape):\n",
    "    # Get the results from NCS\n",
    "    output, userobj = graph.GetResult()\n",
    "\n",
    "    # Get execution time\n",
    "    inference_time = graph.GetGraphOption(mvnc.GraphOption.TIME_TAKEN)\n",
    "\n",
    "    # Deserialize the output into a python dictionary\n",
    "    output_dict = ssd(output, shape)\n",
    "    \n",
    "    return output_dict, inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation. \n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# Utilities to help deserialize the output list from\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "def ssd(output, shape, confidance_threshold=0.6):\n",
    "    \"\"\"---- Deserialize the output from an SSD based network ----\n",
    "    \n",
    "    @param output The NCS returns a list/array in this structure:\n",
    "        First float16: Number of detections\n",
    "        Next 6 values: Unused\n",
    "        Next consecutive batch of 7 values: Detection values\n",
    "          0: Image ID (always 0)\n",
    "          1: Class ID (index into labels.txt)\n",
    "          2: Detection score\n",
    "          3: Box left coordinate (x1) - scaled value between 0 & 1\n",
    "          4: Box top coordinate (y1) - scaled value between 0 & 1\n",
    "          5: Box right coordinate (x2) - scaled value between 0 & 1\n",
    "          6: Box bottom coordinate (y2) - scaled value between 0 & 1\n",
    "\n",
    "    @return output_dict A Python dictionary with the following keys:\n",
    "        output_dict['num_detections'] = Total number of valid detections\n",
    "        output_dict['detection_classes_<X>'] = Class ID of the detected object\n",
    "        output_dict['detection_scores_<X>'] = Percentage of the confidance\n",
    "        output_dict['detection_boxes_<X>'] = A list of 2 tuples [(x1, y1) (x2, y2)]\n",
    "        Where <X> is a zero-index count of num_detections\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary where the deserialized output will be stored\n",
    "    output_dict = {}\n",
    "\n",
    "    # Extract the original image's shape\n",
    "    height, width, channel = shape\n",
    "\n",
    "    # Total number of detections\n",
    "    output_dict['num_detections'] = int(output[0])\n",
    "\n",
    "    # Variable to track number of valid detections\n",
    "    valid_detections = 0\n",
    "\n",
    "    for detection in range(output_dict['num_detections']):\n",
    "\n",
    "        # Skip the first 7 values, and point to the next batch of 7 values\n",
    "        base_index = 7 + (7 * detection)\n",
    "\n",
    "        # Record only those detections whose confidance meets our threshold\n",
    "        if(output[base_index + 2] > confidance_threshold):\n",
    "\n",
    "            output_dict['detection_classes_' + str(valid_detections)] = int(output[base_index + 1])\n",
    "            output_dict['detection_scores_' + str(valid_detections)] = int(output[base_index + 2] * 100)\n",
    "\n",
    "            x = [int(output[base_index + 3] * width), int(output[base_index + 5] * width)]\n",
    "            y = [int(output[base_index + 4] * height), int(output[base_index + 6] * height)]\n",
    "\n",
    "            output_dict['detection_boxes_' + str(valid_detections)] = list(zip(y, x))\n",
    "\n",
    "            valid_detections += 1\n",
    "\n",
    "    # Update total number of detections to valid detections\n",
    "    output_dict['num_detections'] = int(valid_detections)\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ImageClassifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier():\n",
    "    \"\"\" class to make the whole process of taking pictures etc easy\n",
    "    \n",
    "    methods:\n",
    "        ImageClassifier.__init__(...)\n",
    "        ImageClassifier.take_picture_and_start_inference()\n",
    "        ImageClassifier.get_inference_result()\n",
    "        ImageClassifier.close_ncs_device()        \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 graph_file='graph',\n",
    "                 label_file='categories.txt'\n",
    "                 mean=[127.5, 127.5, 127.5],\n",
    "                 scale=0.00789, # 1/127\n",
    "                 dim=[300, 300],\n",
    "                 colourmode='bgr',\n",
    "                 camera_resolution=(640, 480),\n",
    "                 class_of_interest='person'):  # could also be 'dog', 'cat', etc (see categories.txt file)\n",
    "        self.mean = mean\n",
    "        self.scale = scale\n",
    "        self.dim = dim\n",
    "        self.colourmode = colourmode\n",
    "        \n",
    "        # Load the labels file and get the index (=ID) of the class of interest\n",
    "        labels = [line.rstrip('\\n') for line in open(label_file) if line != 'classes\\n']\n",
    "        self.class_of_interest = labels.index(class_of_interest)\n",
    "\n",
    "        # sort out the NCS stuff\n",
    "        self.device = open_ncs_device()\n",
    "        self.graph = load_graph(device, graph_file)\n",
    "        \n",
    "        # initalise the PiCamera\n",
    "        self.camera = picamera.PiCamera()\n",
    "        camera.resolution = camera_resolution\n",
    "        \n",
    "            \n",
    "    def take_picture_and_start_inference(self):\n",
    "        \"\"\" takes a picture and starts the inference, but doesn't wait for a \"\"\"\n",
    "#        self.frame = np.empty((240, 320, 3), dtype=np.uint8) ??\n",
    "        self.frame = picamera.array.PiRGBArray(self.camera)\n",
    "        self.camera.capture(self.frame, self.colourmode, use_video_port=True)\n",
    "\n",
    "        preprocessed_img = pre_process_image(self.frame, self.dim, self.mean, self.scale)\n",
    "\n",
    "        # Load the image as a half-precision floating point array\n",
    "        self.graph.LoadTensor(preprocessed_img, 'user object')\n",
    "\n",
    "\n",
    "    def get_inference_result(self):\n",
    "        output_dict, inference_time = get_inference_result(self.graph, self.frame.array.shape)\n",
    "        \n",
    "        if 'DISPLAY' in os.environ:\n",
    "            display_image(output_dict, self.class_of_interest, self.frame)\n",
    "    \n",
    "        for i in range(output_dict['num_detections']):\n",
    "            if (output_dict.get('detection_classes_%i' % i) == self.class_of_interest):\n",
    "                (y1, x1) = output_dict.get('detection_boxes_' + str(i))[0]\n",
    "                (y2, x2) = output_dict.get('detection_boxes_' + str(i))[1]\n",
    "                bb = (x1 - 0.5, y1 - 0.5), (x2 - 0.5, y2 - 0.5)  # TODO: scaling??\n",
    "                return output_dict, bb, inference_time\n",
    "        \n",
    "        # couldn't find the class of interest\n",
    "        return -1, -1, -1\n",
    "                \n",
    "#         output_dict['detection_classes_<X>'] = Class ID of the detected object\n",
    "#         output_dict['detection_scores_<X>'] = Percentage of the confidance\n",
    "#         output_dict['detection_boxes_<X>'] = A list of 2 tuples [(x1, y1) (x2, y2)]\n",
    "    \n",
    "    def close_ncs_device(self):\n",
    "        self.graph.DeallocateGraph()\n",
    "        self.device.CloseDevice()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for displaying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(output_dict, class_of_interest, frame, capture_screenshots=False):\n",
    "    cur_time = strftime('%Y_%m_%d_%H_%M_%S', localtime())\n",
    "    print('Detections for ' + cur_time)\n",
    "    \n",
    "    # Print the results (each image/frame may have multiple objects)\n",
    "    for i in range(0, output_dict['num_detections']):\n",
    "        \n",
    "        # Filter a specific class/category\n",
    "        if (output_dict.get('detection_classes_' + str(i)) == class_of_interest):\n",
    "            \n",
    "            # Extract top-left & bottom-right coordinates of detected objects\n",
    "            (y1, x1) = output_dict.get('detection_boxes_' + str(i))[0]\n",
    "            (y2, x2) = output_dict.get('detection_boxes_' + str(i))[1]\n",
    "\n",
    "            # Prep string to overlay on the image\n",
    "            display_str = (\n",
    "                labels[output_dict.get('detection_classes_%i' % i)]\n",
    "                + ': %s%%' % output_dict.get('detection_scores_%i' % i))\n",
    "\n",
    "            # Overlay bounding boxes, detection class and scores\n",
    "            frame = draw_bounding_box( \n",
    "                        y1, x1, y2, x2,\n",
    "                        frame,\n",
    "                        thickness=4,\n",
    "                        color=(255, 255, 0),\n",
    "                        display_str=display_str)\n",
    "\n",
    "    if capture_screenshots:\n",
    "        img = PIL.Image.fromarray(frame)\n",
    "        img.save('captures/photo_%s.jpg' % cur_time)\n",
    "\n",
    "    # If a display is available, show image on which inference was performed\n",
    "    if 'DISPLAY' in os.environ:\n",
    "        img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation. \n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# Utilities to help visualize the output from\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "\n",
    "def draw_bounding_box(y1, x1, y2, x2, \n",
    "                      img, \n",
    "                      thickness=4, \n",
    "                      color=(255, 255, 0),\n",
    "                      display_str=()):\n",
    "    \"\"\" draw a bounding box on an image to help visualise the nn output\n",
    "    \n",
    "    Inputs\n",
    "        (x1, y1)  = Top left corner of the bounding box\n",
    "        (x2, y2)  = Bottom right corner of the bounding box\n",
    "        img       = Image/frame represented as numpy array\n",
    "        thickness = Thickness of the bounding box's outline\n",
    "        color     = Color of the bounding box's outline\n",
    "    \"\"\"\n",
    "\n",
    "    img = PIL.Image.fromarray(img)\n",
    "    draw = PIL.ImageDraw.Draw(img)\n",
    "\n",
    "    for x in range(0, thickness):\n",
    "        draw.rectangle([(x1-x, y1-x), (x2-x, y2-x)], outline=color)\n",
    "\n",
    "    font = PIL.ImageFont.load_default()\n",
    "    draw.text((x1, y1), display_str, font=font)\n",
    "\n",
    "    return numpy.array(img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
