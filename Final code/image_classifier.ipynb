{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classifier\n",
    "\n",
    "Contains code for the `ImageClassifer` class, which loads a neural network on the Movidius NCS, takes pictures using a pi cam, passes the (preprocessed) pics through the stick and decodes the result into a bounding box around the category of your choice.\n",
    "\n",
    "Main workflow when importing:\n",
    "1. `import image_classifier`\n",
    "2. `IC = image_classifier.ImageClassifier()`\n",
    "3. Repeat:\n",
    "    - `img_array = IC.take_picture_and_start_inference()`\n",
    "    - `output_dict, bb, inference_time_ms = IC.get_inference_result()`\n",
    "    - `if bb == -1:`\n",
    "        - `    img = PIL.Image.fromarray(img_array)`\n",
    "    - `else:`\n",
    "        - `    (x1, y1), (x2, y2) = bb  # do stuff`\n",
    "\n",
    "---\n",
    "\n",
    "TODO: Much of the code comes from the Movidius GitHub repo, and should be attributed properly!\n",
    "\n",
    "---\n",
    "\n",
    "I find development using a notebook to be quite a bit easier than developing using a regular python file. Unfortunately, you can't import a `.ipynb` as a module. So, here's the workflow:\n",
    "1. Use this file to understand the code and make changes\n",
    "2. When you want to commit a change, click `Kernal > Restart and Clear Output` to remove your outputs + make the file a bit smaller (shows up as fewer lines in the git commit)\n",
    "3. Run the command `jupyter nbconvert --to=python image_classifier.ipynb` to generate a `.py` file which can be imported as a module. Just make sure to remove your debugging code beforehand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import picamera\n",
    "import picamera.array\n",
    "import mvnc.mvncapi as mvnc\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import PIL.ImageFont\n",
    "\n",
    "from time import localtime, strftime, time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the NCS device and load the graph file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation.\n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# DIY smart security camera PoC using Raspberry Pi Camera and\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "\n",
    "def open_ncs_device():\n",
    "\n",
    "    # Look for enumerated NCS device(s); quit program if none found.\n",
    "    devices = mvnc.enumerate_devices()\n",
    "    if len(devices) == 0:\n",
    "        print('No NCS devices found')\n",
    "        quit()\n",
    "\n",
    "    # Get a handle to the first enumerated device and open it\n",
    "    device = mvnc.Device(devices[0])\n",
    "    device.open()\n",
    "\n",
    "    return device\n",
    "\n",
    "def load_graph(device, graph_file_name):\n",
    "    # Read the graph file into a buffer\n",
    "    with open(graph_file_name, mode='rb') as f:\n",
    "        blob = f.read()\n",
    "\n",
    "    # Load the graph buffer into the NCS\n",
    "    graph = mvnc.Graph(graph_file_name)\n",
    "    fifo_in, fifo_out = graph.allocate_with_fifos(device, blob)\n",
    "\n",
    "    return graph, fifo_in, fifo_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the image (resizing, scaling, and mean subtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(frame, dim, mean, scale):\n",
    "    # Read & resize image\n",
    "    # [Image size is defined by choosen network, during training]\n",
    "    img = PIL.Image.fromarray(frame.array).resize(dim)\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "\n",
    "    # Mean subtraction & scaling [A common technique used to center the data]\n",
    "    img = (img - np.float32(mean)) * np.float32(scale)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the inference result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_result(graph, shape, fifo_in, fifo_out):\n",
    "    # Get the results from NCS\n",
    "    output, userobj = fifo_out.read_elem()\n",
    "\n",
    "    # Get execution time\n",
    "    inference_time = np.sum(graph.get_option(mvnc.GraphOption.RO_TIME_TAKEN))\n",
    "\n",
    "    # Deserialize the output into a python dictionary\n",
    "    output_dict = ssd(output, shape)\n",
    "    \n",
    "    return output_dict, inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation. \n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# Utilities to help deserialize the output list from\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "def ssd(output, shape, confidance_threshold=0.6):\n",
    "    \"\"\"---- Deserialize the output from an SSD based network ----\n",
    "    \n",
    "    @param output The NCS returns a list/array in this structure:\n",
    "        First float16: Number of detections\n",
    "        Next 6 values: Unused\n",
    "        Next consecutive batch of 7 values: Detection values\n",
    "          0: Image ID (always 0)\n",
    "          1: Class ID (index into labels.txt)\n",
    "          2: Detection score\n",
    "          3: Box left coordinate (x1) - scaled value between 0 & 1\n",
    "          4: Box top coordinate (y1) - scaled value between 0 & 1\n",
    "          5: Box right coordinate (x2) - scaled value between 0 & 1\n",
    "          6: Box bottom coordinate (y2) - scaled value between 0 & 1\n",
    "\n",
    "    @return output_dict A Python dictionary with the following keys:\n",
    "        output_dict['num_detections'] = Total number of valid detections\n",
    "        output_dict['detection_classes_<X>'] = Class ID of the detected object\n",
    "        output_dict['detection_scores_<X>'] = Percentage of the confidance\n",
    "        output_dict['detection_boxes_<X>'] = A list of 2 tuples [(x1, y1) (x2, y2)]\n",
    "        Where <X> is a zero-index count of num_detections\n",
    "    \"\"\"\n",
    "\n",
    "    output_dict = {}                # Dictionary where the deserialized output will be stored\n",
    "    height, width, channel = shape  # Extract the original image's shape\n",
    "    output_dict['num_detections'] = int(output[0])  # Total number of detections\n",
    "    num_valid_detections = 0\n",
    "\n",
    "    for detection in range(output_dict['num_detections']):\n",
    "        base_index = 7 + (7 * detection)  # Skip the first 7 values\n",
    "\n",
    "        if (output[base_index + 2] > confidance_threshold):\n",
    "            output_dict['detection_classes_' + str(num_valid_detections)] = int(output[base_index + 1])\n",
    "            output_dict['detection_scores_' + str(num_valid_detections)] = int(output[base_index + 2] * 100)\n",
    "\n",
    "            x = [int(output[base_index + 3] * width), int(output[base_index + 5] * width)]\n",
    "            y = [int(output[base_index + 4] * height), int(output[base_index + 6] * height)]\n",
    "\n",
    "            output_dict['detection_boxes_' + str(num_valid_detections)] = list(zip(y, x))\n",
    "\n",
    "            num_valid_detections += 1\n",
    "\n",
    "    # Update total number of detections to valid detections\n",
    "    output_dict['num_detections'] = int(num_valid_detections)\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for displaying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(output_dict, class_of_interest, frame, labels, capture_screenshots=False):\n",
    "    # Print the results (each image/frame may have multiple objects)\n",
    "    for i in range(0, output_dict['num_detections']):\n",
    "        \n",
    "        if (output_dict.get('detection_classes_' + str(i)) == class_of_interest):\n",
    "            \n",
    "            # Extract top-left & bottom-right coordinates of detected objects\n",
    "            (y1, x1) = output_dict.get('detection_boxes_' + str(i))[0]\n",
    "            (y2, x2) = output_dict.get('detection_boxes_' + str(i))[1]\n",
    "\n",
    "            # Prep string to overlay on the image\n",
    "            display_str = (\n",
    "                labels[output_dict.get('detection_classes_%i' % i)]\n",
    "                + ': %s%%' % output_dict.get('detection_scores_%i' % i))\n",
    "\n",
    "            # Overlay bounding boxes, detection class and scores\n",
    "            frame = draw_bounding_box( \n",
    "                        y1, x1, y2, x2,\n",
    "                        frame,\n",
    "                        thickness=4,\n",
    "                        color=(255, 255, 0),\n",
    "                        display_str=display_str)\n",
    "\n",
    "    if capture_screenshots:\n",
    "        img = PIL.Image.fromarray(frame)\n",
    "        img.save('captures/photo_%s.jpg' % cur_time)\n",
    "\n",
    "    # If a display is available, show image on which inference was performed\n",
    "    if 'DISPLAY' in os.environ:\n",
    "        img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation. \n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# Utilities to help visualize the output from\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "\n",
    "def draw_bounding_box(y1, x1, y2, x2, \n",
    "                      img, \n",
    "                      thickness=4, \n",
    "                      color=(255, 255, 0),\n",
    "                      display_str=()):\n",
    "    \"\"\" draw a bounding box on an image to help visualise the nn output\n",
    "    \n",
    "    Inputs\n",
    "        (x1, y1)  = Top left corner of the bounding box\n",
    "        (x2, y2)  = Bottom right corner of the bounding box\n",
    "        img       = Image/frame represented as numpy array\n",
    "        thickness = Thickness of the bounding box's outline\n",
    "        color     = Color of the bounding box's outline\n",
    "    \"\"\"\n",
    "\n",
    "    img = PIL.Image.fromarray(img)\n",
    "    draw = PIL.ImageDraw.Draw(img)\n",
    "\n",
    "    for x in range(0, thickness):\n",
    "        draw.rectangle([(x1-x, y1-x), (x2-x, y2-x)], outline=color)\n",
    "\n",
    "    font = PIL.ImageFont.load_default()\n",
    "    draw.text((x1, y1), display_str, font=font)\n",
    "\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_angle(pixel, img_size, cam_angle_deg):\n",
    "    \"\"\" convert a pixel value to an angle in degrees\n",
    "    inputs:\n",
    "        pixel:              a value from 0 to img_size\n",
    "        img_size:           the total number of pixels along that axis of the image\n",
    "        cam_angle_deg:      the angular width of camera in degrees\n",
    "        \n",
    "    output:\n",
    "        angle:      0deg = when pixel is directly ahead, positive/negative = right/left of center\n",
    "    \"\"\"\n",
    "    norm_pixel = (2*pixel/img_size) - 1  # now in range [-1, 1]\n",
    "    angle = np.arctan(norm_pixel * np.tan(np.deg2rad(cam_angle_deg/2)))\n",
    "    return np.rad2deg(angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ImageClassifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier():\n",
    "    \"\"\" class to make the whole process of taking pictures etc easy\n",
    "    \n",
    "    methods:\n",
    "        ImageClassifier.__init__(...)\n",
    "        ImageClassifier.take_picture_and_start_inference()\n",
    "        ImageClassifier.get_inference_result()\n",
    "        ImageClassifier.close_ncs_device()        \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 graph_file='graph',\n",
    "                 label_file='categories.txt',\n",
    "                 mean=[127.5, 127.5, 127.5],\n",
    "                 scale=0.00789, # 1/127\n",
    "                 dim=[300, 300],\n",
    "                 colourmode='rgb',\n",
    "                 camera_resolution=(640, 480),\n",
    "                 camera_FOV=(62.2, 48.8),\n",
    "                 class_of_interest='person'):  # could also be 'dog', 'cat', etc (see categories.txt file)\n",
    "        self.mean = mean\n",
    "        self.scale = scale\n",
    "        self.dim = dim\n",
    "        self.colourmode = colourmode\n",
    "        self.camera_resolution = camera_resolution\n",
    "        self.camera_FOV = camera_FOV\n",
    "        \n",
    "        # Load the labels file and get the index (=ID) of the class of interest\n",
    "        self.labels = [line.rstrip('\\n') for line in open(label_file) if line != 'classes\\n']\n",
    "        self.class_of_interest = self.labels.index(class_of_interest)\n",
    "\n",
    "        # sort out the NCS stuff\n",
    "        self.device = open_ncs_device()\n",
    "        self.graph, self.fifo_in, self.fifo_out = load_graph(self.device, graph_file)\n",
    "        \n",
    "        \n",
    "    def take_picture_and_start_inference(self):\n",
    "        \"\"\" takes a picture and starts the inference, but doesn't wait for a \"\"\"\n",
    "        with picamera.PiCamera(resolution=self.camera_resolution) as camera:\n",
    "            try:\n",
    "                self.frame = picamera.array.PiRGBArray(camera)\n",
    "                camera.capture(self.frame, self.colourmode, use_video_port=True)\n",
    "            except:\n",
    "                print('Couldn\\'t capture image')\n",
    "                return [-1]\n",
    "\n",
    "            preprocessed_img = pre_process_image(self.frame, self.dim, self.mean, self.scale)\n",
    "\n",
    "            # Load the image as a half-precision floating point array\n",
    "            self.graph.queue_inference_with_fifo_elem(self.fifo_in, self.fifo_out, preprocessed_img, None)\n",
    "\n",
    "            return self.frame.array\n",
    "\n",
    "\n",
    "    def get_inference_result(self):\n",
    "        output_dict, inference_time_ms = get_inference_result(self.graph,\n",
    "                                                           self.frame.array.shape,\n",
    "                                                           self.fifo_in,\n",
    "                                                           self.fifo_out)\n",
    "        \n",
    "#         if 'DISPLAY' in os.environ:\n",
    "#             display_image(output_dict, self.class_of_interest, self.frame, self.labels)\n",
    "        \n",
    "        for i in range(output_dict['num_detections']):\n",
    "            if (output_dict.get('detection_classes_%i' % i) == self.class_of_interest):\n",
    "                (y1, x1) = output_dict.get('detection_boxes_' + str(i))[0]\n",
    "                (y2, x2) = output_dict.get('detection_boxes_' + str(i))[1]\n",
    "                bb = (x1, y1), (x2, y2)\n",
    "                \n",
    "                w, h = self.camera_resolution\n",
    "                cam_width = self.camera_FOV[0]\n",
    "                cam_height = self.camera_FOV[1]\n",
    "                x1_angle = pixel_to_angle(x1, w, cam_width)\n",
    "                x2_angle = pixel_to_angle(x2, w, cam_width)\n",
    "                y1_angle = pixel_to_angle(y1, h, cam_height)\n",
    "                y2_angle = pixel_to_angle(y2, h, cam_height)\n",
    "                bb_angles = ((x1_angle, y1_angle), (x2_angle, y2_angle))\n",
    "                \n",
    "                return output_dict, bb, bb_angles, inference_time_ms\n",
    "\n",
    "        # couldn't find the class of interest\n",
    "        return output_dict, -1, -1, inference_time_ms        \n",
    "\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.fifo_in.destroy()\n",
    "        self.fifo_out.destroy()\n",
    "\n",
    "        self.graph.destroy()\n",
    "\n",
    "        self.device.close()\n",
    "        self.device.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IC = ImageClassifier(graph_file='../Models/MobileNet_SSD_caffe/graph',\n",
    "                     label_file='../Models/MobileNet_SSD_caffe/categories.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaw_arr = []\n",
    "pitch_arr = []\n",
    "inference_time_arr = []\n",
    "loop_time_arr = []\n",
    "t = time()\n",
    "\n",
    "for i in range(100):\n",
    "    img_array = IC.take_picture_and_start_inference()\n",
    "    output_dict, bb, bb_angles, inference_time_ms = IC.get_inference_result()\n",
    "    \n",
    "    (phi_x1, phi_y1), (phi_x2, phi_y2) = bb_angles\n",
    "    phi_yaw = (phi_x1 + phi_x2)/2\n",
    "    phi_pitch = (phi_y1 + phi_y2)/2\n",
    "    yaw_arr.append(phi_yaw)\n",
    "    pitch_arr.append(phi_pitch)\n",
    "    \n",
    "    Ts_arr.append(inference_time_ms)\n",
    "    \n",
    "    loop_time_arr.append(time() - t)\n",
    "    t = time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# img_array = IC.take_picture_and_start_inference()\n",
    "# output_dict, bb, inference_time_ms = IC.get_inference_result()\n",
    "\n",
    "# print(output_dict)\n",
    "# print(bb)\n",
    "# print(inference_time_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if bb == -1:\n",
    "#     img = PIL.Image.fromarray(img_array)\n",
    "# else:\n",
    "#     (x1, y1), (x2, y2) = bb\n",
    "#     img = PIL.Image.fromarray(img_array)\n",
    "#     img = PIL.Image.fromarray(draw_bounding_box(y1, x1, y2, x2, img_array))\n",
    "\n",
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# del IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# timeit.timeit(my_func, number=10)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_func():\n",
    "#     with picamera.PiCamera(resolution=(300,300)) as camera:\n",
    "#         frame = picamera.array.PiRGBArray(camera)\n",
    "#         camera.capture(frame, 'rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_func()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
