{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classifier\n",
    "\n",
    "Contains code for the `ImageClassifer` class, which loads a neural network on the Movidius NCS, takes pictures using a pi cam, passes the (preprocessed) pics through the stick and decodes the result into a bounding box around the category of your choice.\n",
    "\n",
    "https://picamera.readthedocs.io/en/latest/fov.html\n",
    "\n",
    "Main workflow when importing:\n",
    "1. `import image_classifier`\n",
    "2. `IC = image_classifier.ImageClassifier()`\n",
    "3. Repeat:\n",
    "    - `bb, bb_angles = IC.get_result()`\n",
    "    - `if bb == -1:`\n",
    "        - `    pass`\n",
    "    - `else:`\n",
    "        - `    (x1, y1), (x2, y2) = bb  # do stuff`\n",
    "\n",
    "---\n",
    "\n",
    "TODO: Some of the code comes from the Movidius GitHub repo, and should be attributed properly!\n",
    "\n",
    "---\n",
    "\n",
    "I find development using a notebook to be quite a bit easier than developing using a regular python file. Unfortunately, you can't import a `.ipynb` as a module. So, here's the workflow:\n",
    "1. Use this file to understand the code and make changes\n",
    "2. When you want to commit a change, click `Kernal > Restart and Clear Output` to remove your outputs + make the file a bit smaller (shows up as fewer lines in the git commit)\n",
    "3. Run the command `jupyter nbconvert --to=python image_classifier.ipynb` to generate a `.py` file which can be imported as a module. Just make sure that any debugging code doesn't run if this is imported as a module into another file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time, multiprocessing, numpy as np, PIL.Image\n",
    "import picamera, picamera.array\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save (some) photos to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PhotoSaver():\n",
    "    \"\"\" class to help save every `n` photos passed to it \"\"\"\n",
    "    def __init__(self, every_n_photos=1, output_dir='logged_photos/'):\n",
    "        self.every_n_photos = every_n_photos\n",
    "        self.n = 0\n",
    "        self.i = 0        \n",
    "        \n",
    "        self.output_dir = output_dir[:-1] # [:-1] to strip the '/'\n",
    "        i = 0\n",
    "        while self.output_dir in os.listdir():\n",
    "            self.output_dir = output_dir[:-1] + str(i)\n",
    "            i += 1\n",
    "        \n",
    "        os.mkdir(self.output_dir)\n",
    "        self.output_dir = self.output_dir + '/'\n",
    "    \n",
    "    def save_photo(self, arr):\n",
    "        np.save(self.output_dir + 'photo_%i.npy' % self.i, arr)\n",
    "        self.i += 1\n",
    "    \n",
    "    def maybe_save_photo(self, arr):\n",
    "        if self.n > self.every_n_photos:\n",
    "            self.n = 0\n",
    "            np.save(self.output_dir + 'photo_%i.npy' % self.i, arr)\n",
    "            self.i += 1\n",
    "        else:\n",
    "            self.n += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ImageClassifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def picam_streamer(image_queue, e, # for multiprocessing\n",
    "                  camera_resolution, colourmode,\n",
    "                  nn_shape, scale, mean,\n",
    "                  debug):\n",
    "\n",
    "    if debug: print('picam_streamer: initialising camera')\n",
    "    with picamera.PiCamera(resolution=camera_resolution, framerate=40, sensor_mode=5) as camera:\n",
    "        frame = picamera.array.PiRGBArray(camera, size=(320, 304)) # closest to nn_shape of (300,300)\n",
    "        cont_capture = camera.capture_continuous(frame, colourmode,\n",
    "                                                 resize=(320, 304), # use GPU for resizing - will resize to nn_shape later\n",
    "                                                 use_video_port=True)\n",
    "\n",
    "        next(cont_capture)  # get the next frame in the continuous capture\n",
    "        \n",
    "        while True:\n",
    "            if debug: t = time.time()\n",
    "\n",
    "            if e.is_set():\n",
    "                print('picam_streamer: shutting down')\n",
    "                del cont_capture\n",
    "                del frame\n",
    "                break\n",
    "            \n",
    "            frame.seek(0)\n",
    "            frame.truncate(0)\n",
    "            next(cont_capture)\n",
    "            img = np.array(PIL.Image.fromarray(frame.array).resize(nn_shape, PIL.Image.ANTIALIAS))\n",
    "            photo_time = time.time()\n",
    "            if debug: print('picam_streamer: time to capture + resize photo: %d [ms]' % ((photo_time-t)*1000))\n",
    "            \n",
    "            if debug: _t = time.time()\n",
    "            preprocessed_img = (img - np.float32(mean)) * np.float32(scale)\n",
    "            if debug: print('picam_streamer: time to preprocess image: %d [ms]' % ((time.time()-_t)*1000))\n",
    "            \n",
    "            if image_queue.qsize() <= 2:\n",
    "                image_queue.put(preprocessed_img)\n",
    "                image_queue.put(photo_time)\n",
    "            elif debug:\n",
    "                print('picam_streamer: skipping adding photo.  image_queue.qsize() =', image_queue.qsize())\n",
    "\n",
    "            if debug: print('picam_streamer: total loop time: %d [ms]' % ((time.time()-t)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_infer(image_queue, dict_queue, e, # for multiprocessing\n",
    "             graph_filename,\n",
    "             nn_shape,\n",
    "             confidance_threshold,\n",
    "             photo_logging_params,\n",
    "             debug):\n",
    "\n",
    "    if debug: print('nn_infer: importing MVNC library and opening NCS device')\n",
    "    import mvnc.mvncapi as mvnc  # have to import the library here to get the thing to work, for some reason\n",
    "    \n",
    "    ## Start of Movidius code:\n",
    "    devices = mvnc.enumerate_devices()\n",
    "    if len(devices) == 0:\n",
    "        print('nn_infer: no NCS devices found. Shutting down.')\n",
    "        e.set()\n",
    "        exit()\n",
    "\n",
    "    # Get a handle to the first enumerated device and open it\n",
    "    device = mvnc.Device(devices[0])\n",
    "    device.open()\n",
    "\n",
    "    # Read the graph file into a buffer\n",
    "    with open(graph_filename, mode='rb') as f:\n",
    "        blob = f.read()\n",
    "\n",
    "    # Load the graph buffer into the NCS\n",
    "    graph = mvnc.Graph(graph_filename)\n",
    "    fifo_in, fifo_out = graph.allocate_with_fifos(device, blob)\n",
    "    ## End of Movidius code\n",
    "    \n",
    "    PS = PhotoSaver(photo_logging_params[0], photo_logging_params[1]) # save every n=10 photos passed to this function\n",
    "\n",
    "    while True:\n",
    "        if debug: t = time.time()\n",
    "            \n",
    "        if e.is_set():\n",
    "            print('nn_infer: shutting down')\n",
    "            break\n",
    "\n",
    "        preprocessed_img = image_queue.get()\n",
    "        photo_time = image_queue.get()\n",
    "\n",
    "        if debug: _t = time.time()\n",
    "        graph.queue_inference_with_fifo_elem(fifo_in, fifo_out, preprocessed_img, None)\n",
    "        if debug: print('nn_infer: queueing time: %d [ms]' % ((time.time()-_t)*1000))\n",
    "        \n",
    "        if debug: _t = time.time()\n",
    "        PS.maybe_save_photo(preprocessed_img)\n",
    "        if debug: print('nn_infer: save photo time: %d [ms]' % ((time.time()-_t)*1000))\n",
    "\n",
    "        ## Start of Movidius code:\n",
    "        if debug: _t = time.time()\n",
    "        output, userobj = fifo_out.read_elem()\n",
    "        if debug: print('nn_infer: result retrieval time: %d [ms]' % ((time.time()-_t)*1000))\n",
    "\n",
    "        # Deserialize the output into a python dictionary\n",
    "        output_dict = utils.deserialize_ssd(output, nn_shape, confidance_threshold) # this takes very little time\n",
    "        ## End of Movidius code\n",
    "        \n",
    "        output_dict['photo_time'] = photo_time\n",
    "        dict_queue.put(output_dict)\n",
    "        if debug: print('nn_infer: dict_queue.qsize() =', dict_queue.qsize())\n",
    "        if debug: print('nn_infer: loop time: %d [ms]' % ((time.time()-t)*1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier():\n",
    "    def __init__(self,\n",
    "                 graph_filename='graph',\n",
    "                 label_filename='categories.txt',  # must correspond to the specific network\n",
    "                 class_of_interest='person',\n",
    "                 colourmode='rgb',\n",
    "                 camera_resolution=(1280, 720),# (width, height)\n",
    "                 nn_shape=(300, 300),          # (width, height)\n",
    "                 camera_FOV_deg=(62.2, 48.8),  # (width, height)):\n",
    "                 mean=(127.5, 127.5, 127.5),   # depends on the colourmode\n",
    "                 scale=0.00789,                # = 1/127\n",
    "                 confidance_threshold=0.4,     # not that this isn't really a percentage as we know it - just a number that\n",
    "                                               # represents prediction confidance in some way\n",
    "                 photo_logging_params=(10, 'photo_logging/'), # save every `10` photos in `photo_logging/` dir\n",
    "                 debug=False):\n",
    "        \n",
    "        labels = [line.rstrip('\\n') for line in open(label_filename) if line != 'classes\\n']\n",
    "        self.class_of_interest = labels.index(class_of_interest) # note conversion from string to ID (int)\n",
    "        self.nn_shape = nn_shape\n",
    "        self.camera_FOV_deg = camera_FOV_deg\n",
    "\n",
    "        self.image_queue = multiprocessing.Queue()\n",
    "        self.dict_queue = multiprocessing.Queue()\n",
    "        self.e = multiprocessing.Event()\n",
    "        \n",
    "        self.infer_process = multiprocessing.Process(\n",
    "                                                target=nn_infer,\n",
    "                                                args=(self.image_queue, self.dict_queue, self.e,\n",
    "                                                      graph_filename,\n",
    "                                                      nn_shape,\n",
    "                                                      confidance_threshold,\n",
    "                                                      photo_logging_params,\n",
    "                                                      debug))\n",
    "        \n",
    "        self.photo_process = multiprocessing.Process(\n",
    "                                                target=picam_streamer,\n",
    "                                                args=(self.image_queue, self.e,\n",
    "                                                      camera_resolution, colourmode,\n",
    "                                                      nn_shape, scale, mean,\n",
    "                                                      debug))\n",
    "\n",
    "        self.infer_process.start()\n",
    "        self.photo_process.start()\n",
    "        if debug: print('ImageClassifier: started child processes')\n",
    "    \n",
    "    def get_result(self, debug=False):\n",
    "        if debug: print('ImageClassifier: getting output dict')\n",
    "        output_dict = self.dict_queue.get()\n",
    "        bb, bb_angles = utils.output_dict_to_bb_and_angles(output_dict,\n",
    "                                                           self.class_of_interest,\n",
    "                                                           self.nn_shape,\n",
    "                                                           self.camera_FOV_deg)\n",
    "        return bb, bb_angles, output_dict['photo_time']\n",
    "    \n",
    "    def close(self): self.__del__()\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.e.set()  # setting the flag signals the other processes to shut down\n",
    "        time.sleep(2)\n",
    "        self.image_queue.close()\n",
    "        self.dict_queue.close()\n",
    "        del self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
