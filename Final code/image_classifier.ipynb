{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classifier\n",
    "\n",
    "Contains code for the `ImageClassifer` class, which loads a neural network on the Movidius NCS, takes pictures using a pi cam, passes the (preprocessed) pics through the stick and decodes the result into a bounding box around the category of your choice.\n",
    "\n",
    "Main workflow when importing:\n",
    "1. `import image_classifier`\n",
    "2. `IC = image_classifier.ImageClassifier()`\n",
    "3. Repeat:\n",
    "    - `img_array = IC.take_picture_and_start_inference()`\n",
    "    - `output_dict, bb, inference_time_ms = IC.get_inference_result()`\n",
    "    - `if bb == -1:`\n",
    "        - `    img = PIL.Image.fromarray(img_array)`\n",
    "    - `else:`\n",
    "        - `    (x1, y1), (x2, y2) = bb  # do stuff`\n",
    "\n",
    "---\n",
    "\n",
    "TODO: Much of the code comes from the Movidius GitHub repo, and should be attributed properly!\n",
    "\n",
    "---\n",
    "\n",
    "I find development using a notebook to be quite a bit easier than developing using a regular python file. Unfortunately, you can't import a `.ipynb` as a module. So, here's the workflow:\n",
    "1. Use this file to understand the code and make changes\n",
    "2. When you want to commit a change, click `Kernal > Restart and Clear Output` to remove your outputs + make the file a bit smaller (shows up as fewer lines in the git commit)\n",
    "3. Run the command `jupyter nbconvert --to=python image_classifier.ipynb` to generate a `.py` file which can be imported as a module. Just make sure to remove your debugging code beforehand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import picamera, picamera.array\n",
    "import mvnc.mvncapi as mvnc\n",
    "import PIL.Image, PIL.ImageDraw, PIL.ImageFont\n",
    "from apscheduler.schedulers.background import BackgroundScheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the NCS device and load the graph file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation.\n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# DIY smart security camera PoC using Raspberry Pi Camera and\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "\n",
    "def open_ncs_device():\n",
    "\n",
    "    # Look for enumerated NCS device(s); quit program if none found.\n",
    "    devices = mvnc.enumerate_devices()\n",
    "    if len(devices) == 0:\n",
    "        print('No NCS devices found')\n",
    "        exit()\n",
    "\n",
    "    # Get a handle to the first enumerated device and open it\n",
    "    device = mvnc.Device(devices[0])\n",
    "    device.open()\n",
    "\n",
    "    return device\n",
    "\n",
    "def load_graph(device, graph_file_name):\n",
    "    # Read the graph file into a buffer\n",
    "    with open(graph_file_name, mode='rb') as f:\n",
    "        blob = f.read()\n",
    "\n",
    "    # Load the graph buffer into the NCS\n",
    "    graph = mvnc.Graph(graph_file_name)\n",
    "    fifo_in, fifo_out = graph.allocate_with_fifos(device, blob)\n",
    "\n",
    "    return graph, fifo_in, fifo_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the image (resizing, scaling, and mean subtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(img, dim, mean, scale):\n",
    "#     img = PIL.Image.fromarray(frame.array)#.resize(dim)\n",
    "#     img = np.array(img, dtype=np.float32)\n",
    "#     if img.shape != (dim[0], dim[1], 3):\n",
    "#         img = img[:dim[0], :dim[1], :]\n",
    "#         print('resizing in preprocess function')\n",
    "\n",
    "    # Mean subtraction & scaling [A common technique used to center the data]\n",
    "    img = (img - np.float32(mean)) * np.float32(scale)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the inference result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_result(graph, shape, fifo_in, fifo_out, confidance_threshold=0.6):\n",
    "    # Get the results from NCS\n",
    "    output, userobj = fifo_out.read_elem()\n",
    "\n",
    "    # Get execution time\n",
    "    inference_time = np.sum(graph.get_option(mvnc.GraphOption.RO_TIME_TAKEN))\n",
    "\n",
    "    # Deserialize the output into a python dictionary\n",
    "    output_dict = deserialize_ssd(output, shape, confidance_threshold)\n",
    "    \n",
    "    return output_dict, inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation. \n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# Utilities to help deserialize the output list from\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "def deserialize_ssd(output, shape, confidance_threshold):\n",
    "    \"\"\"---- Deserialize the output from an SSD based network ----\n",
    "    \n",
    "    @param output The NCS returns a list/array in this structure:\n",
    "        First float16: Number of detections\n",
    "        Next 6 values: Unused\n",
    "        Next consecutive batch of 7 values: Detection values\n",
    "          0: Image ID (always 0)\n",
    "          1: Class ID (index into labels.txt)\n",
    "          2: Detection score\n",
    "          3: Box left coordinate (x1) - scaled value between 0 & 1\n",
    "          4: Box top coordinate (y1) - scaled value between 0 & 1\n",
    "          5: Box right coordinate (x2) - scaled value between 0 & 1\n",
    "          6: Box bottom coordinate (y2) - scaled value between 0 & 1\n",
    "\n",
    "    @return output_dict A Python dictionary with the following keys:\n",
    "        output_dict['num_detections'] = Total number of valid detections\n",
    "        output_dict['detection_classes_<X>'] = Class ID of the detected object\n",
    "        output_dict['detection_scores_<X>'] = Percentage of the confidance\n",
    "        output_dict['detection_boxes_<X>'] = A list of 2 tuples [(x1, y1) (x2, y2)]\n",
    "        Where <X> is a zero-index count of num_detections\n",
    "    \"\"\"\n",
    "\n",
    "    output_dict = {}                # Dictionary where the deserialized output will be stored\n",
    "    height, width, channel = shape  # Extract the original image's shape\n",
    "    output_dict['num_detections'] = int(output[0])  # Total number of detections\n",
    "    num_valid_detections = 0\n",
    "\n",
    "    for detection in range(output_dict['num_detections']):\n",
    "        base_index = 7 + (7 * detection)  # Skip the first 7 values\n",
    "\n",
    "        if (output[base_index + 2] > confidance_threshold):\n",
    "            output_dict['detection_classes_' + str(num_valid_detections)] = int(output[base_index + 1])\n",
    "            output_dict['detection_scores_' + str(num_valid_detections)] = int(output[base_index + 2] * 100)\n",
    "\n",
    "            x = [int(output[base_index + 3] * width), int(output[base_index + 5] * width)]\n",
    "            y = [int(output[base_index + 4] * height), int(output[base_index + 6] * height)]\n",
    "\n",
    "            output_dict['detection_boxes_' + str(num_valid_detections)] = list(zip(y, x))\n",
    "\n",
    "            num_valid_detections += 1\n",
    "\n",
    "    # Update total number of detections to valid detections\n",
    "    output_dict['num_detections'] = int(num_valid_detections)\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_dict_to_bb_and_angles(output_dict, class_of_interest, camera_resolution, camera_FOV):\n",
    "    for i in range(output_dict['num_detections']):\n",
    "        if (output_dict.get('detection_classes_%i' % i) == class_of_interest):\n",
    "            (y1, x1) = output_dict.get('detection_boxes_' + str(i))[0]\n",
    "            (y2, x2) = output_dict.get('detection_boxes_' + str(i))[1]\n",
    "            bb = (x1, y1), (x2, y2)\n",
    "\n",
    "            w, h = camera_resolution\n",
    "            cam_width = camera_FOV[0]\n",
    "            cam_height = camera_FOV[1]\n",
    "            x1_angle = pixel_to_angle(x1, w, cam_width)\n",
    "            x2_angle = pixel_to_angle(x2, w, cam_width)\n",
    "            y1_angle = pixel_to_angle(y1, h, cam_height)\n",
    "            y2_angle = pixel_to_angle(y2, h, cam_height)\n",
    "            bb_angles = ((x1_angle, y1_angle), (x2_angle, y2_angle))\n",
    "\n",
    "            return bb, bb_angles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for displaying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(output_dict, class_of_interest, frame, labels, capture_screenshots=False):\n",
    "    # Print the results (each image/frame may have multiple objects)\n",
    "    for i in range(output_dict['num_detections']):\n",
    "        \n",
    "        if (output_dict.get('detection_classes_' + str(i)) == class_of_interest):\n",
    "            \n",
    "            # Extract top-left & bottom-right coordinates of detected objects\n",
    "            (y1, x1) = output_dict.get('detection_boxes_' + str(i))[0]\n",
    "            (y2, x2) = output_dict.get('detection_boxes_' + str(i))[1]\n",
    "\n",
    "            # Prep string to overlay on the image\n",
    "            display_str = (labels[output_dict.get('detection_classes_%i' % i)]\n",
    "                           + ': %s%%' % output_dict.get('detection_scores_%i' % i))\n",
    "\n",
    "            # Overlay bounding boxes, detection class and scores\n",
    "            frame = draw_bounding_box( \n",
    "                        y1, x1, y2, x2,\n",
    "                        frame, display_str=display_str)\n",
    "\n",
    "    if capture_screenshots:\n",
    "        img = PIL.Image.fromarray(frame)\n",
    "        img.save('captures/photo_%s.jpg' % cur_time)\n",
    "\n",
    "    # If a display is available, show image on which inference was performed\n",
    "    if 'DISPLAY' in os.environ:\n",
    "        img.show()\n",
    "\n",
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation. \n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# Utilities to help visualize the output from\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "def draw_bounding_box(y1, x1, y2, x2, \n",
    "                      img, \n",
    "                      thickness=4, \n",
    "                      color=(255, 255, 0),\n",
    "                      display_str=()):\n",
    "    \"\"\" draw a bounding box on an image to help visualise the nn output\n",
    "    \n",
    "    Inputs\n",
    "        (x1, y1)  = Top left corner of the bounding box\n",
    "        (x2, y2)  = Bottom right corner of the bounding box\n",
    "        img       = Image/frame represented as numpy array\n",
    "        thickness = Thickness of the bounding box's outline\n",
    "        color     = Color of the bounding box's outline\n",
    "    \"\"\"\n",
    "    img = PIL.Image.fromarray(img)\n",
    "    draw = PIL.ImageDraw.Draw(img)\n",
    "\n",
    "    for x in range(0, thickness):\n",
    "        draw.rectangle([(x1-x, y1-x), (x2-x, y2-x)], outline=color)\n",
    "\n",
    "    font = PIL.ImageFont.load_default()\n",
    "    draw.text((x1, y1), display_str, font=font)\n",
    "\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_angle(pixel, img_size, cam_angle_deg):\n",
    "    \"\"\" convert a pixel value to an angle in degrees\n",
    "    inputs:\n",
    "        pixel:              a value from 0 to img_size\n",
    "        img_size:           the total number of pixels along that axis of the image\n",
    "        cam_angle_deg:      the angular width of camera in degrees\n",
    "        \n",
    "    output:\n",
    "        angle:      0deg = when pixel is directly ahead, positive/negative = right/left of center\n",
    "    \"\"\"\n",
    "    norm_pixel = (2*pixel/img_size) - 1  # now in range [-1, 1]\n",
    "    angle = np.arctan(norm_pixel * np.tan(np.deg2rad(cam_angle_deg/2)))\n",
    "    return np.rad2deg(angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ImageClassifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier():\n",
    "    \"\"\" class to make the whole process of taking pictures etc easy\n",
    "    \n",
    "    methods:\n",
    "        ImageClassifier.__init__(...)\n",
    "        ImageClassifier.take_picture_and_start_inference()\n",
    "        ImageClassifier.get_inference_result()\n",
    "        ImageClassifier.__del__()\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 graph_file='graph',\n",
    "                 label_file='categories.txt',  # must correspond to the specific network\n",
    "                 mean=(127.5, 127.5, 127.5),   # depends on the colourmode\n",
    "                 scale=0.00789,                # = 1/127\n",
    "                 nn_dim=(300, 300),            # (width, height)\n",
    "                 colourmode='rgb',\n",
    "                 camera_resolution=(1640, 922),# (width, height)\n",
    "                 camera_FOV=(62.2, 48.8),      # (width, height)\n",
    "                 class_of_interest='person',   # could also be 'dog', 'cat', etc (see categories.txt file)\n",
    "                 debug=False):\n",
    "        \n",
    "        ##### COPY ARGS TO OBJECT #####\n",
    "        self.mean = mean\n",
    "        self.scale = scale\n",
    "        self.dim = nn_dim\n",
    "        self.colourmode = colourmode\n",
    "        self.camera_resolution = camera_resolution\n",
    "        self.camera_FOV = camera_FOV\n",
    "        self.debug = debug\n",
    "        \n",
    "        ##### LOAD THE LABELS FILE #####\n",
    "        self.labels = [line.rstrip('\\n') for line in open(label_file) if line != 'classes\\n']\n",
    "        self.class_of_interest = self.labels.index(class_of_interest) # note conversion from string to ID (int)\n",
    "        \n",
    "        ##### OPEN AND INIT THE NCS #####\n",
    "        self.device = open_ncs_device()\n",
    "        self.graph, self.fifo_in, self.fifo_out = load_graph(self.device, graph_file)\n",
    "        \n",
    "        ##### OPEN THE CAMERA AND START STREAMING #####\n",
    "        self.camera = picamera.PiCamera(resolution=self.camera_resolution, framerate=90)\n",
    "        self.frame = picamera.array.PiRGBArray(self.camera, size=nn_dim)\n",
    "        self.cont_capture = self.camera.capture_continuous(self.frame, colourmode, resize=nn_dim, use_video_port=True)# use GPU for resizing\n",
    "        \n",
    "        ##### MULTITHREADING #####\n",
    "        self.scheduler = BackgroundScheduler()\n",
    "        \n",
    "        self.job_take_pics            = self.scheduler.add_job(self.take_pics, 'interval', seconds=10, max_instances=1) #8 FPS\n",
    "        self.job_preprocess_and_queue = self.scheduler.add_job(self.preprocess_and_queue, 'interval', seconds=10, max_instances=1)\n",
    "        self.job_get_results          = self.scheduler.add_job(self.get_inference_result, 'interval', seconds=10, max_instances=1)\n",
    "        \n",
    "        self.take_pics_done = False\n",
    "        self.preprocess_and_queue_done = False\n",
    "        self.results_are_ready = False\n",
    "        \n",
    "        self.scheduler.start()\n",
    "        \n",
    "        \n",
    "    def take_pics(self):\n",
    "        \"\"\" launches every 0.125 seconds = 8 Hz\"\"\"\n",
    "        while True:\n",
    "            self.frame.seek(0)\n",
    "            self.frame.truncate(0)\n",
    "            next(self.cont_capture)  # next frame in the continuous capture\n",
    "\n",
    "            self.take_pics_done = True\n",
    "    \n",
    "    \n",
    "    def preprocess_and_queue(self, debug=False):\n",
    "        while True:\n",
    "            if self.take_pics_done is True:\n",
    "                preprocessed_img = pre_process_image(self.frame.array, self.dim, self.mean, self.scale)\n",
    "                self.graph.queue_inference_with_fifo_elem(self.fifo_in, self.fifo_out, preprocessed_img, None)\n",
    "\n",
    "                self.take_pics_done = False\n",
    "                self.preprocess_and_queue_done = True\n",
    "\n",
    "\n",
    "    def get_inference_result(self):\n",
    "        while True:\n",
    "            if self.preprocess_and_queue_done is True:\n",
    "                self.output_dict, inference_time_ms = get_inference_result(self.graph,\n",
    "                                                                           self.frame.array.shape,\n",
    "                                                                           self.fifo_in,\n",
    "                                                                           self.fifo_out)\n",
    "\n",
    "                self.bb, self.bb_angles = output_dict_to_bb_and_angles(output_dict,\n",
    "                                                             self.class_of_interest,\n",
    "                                                             self.camera_resolution,\n",
    "                                                             self.camera_FOV)\n",
    "\n",
    "                self.new_results_are_ready = True\n",
    "    \n",
    "    \n",
    "    def get_results(self):\n",
    "        if self.new_results_are_ready is True:\n",
    "            self.new_results_are_ready = False\n",
    "            return self.output_dict, self.bb, self.bb_angles\n",
    "        else:\n",
    "            return -1, -1, -1\n",
    "\n",
    "    def close(self): self.__del__()\n",
    "    \n",
    "    def __del__(self):\n",
    "        print('Closing threads...')\n",
    "        self.job_take_pics.close()\n",
    "        self.job_preprocess_and_queue.close()\n",
    "        self.job_get_results.close()\n",
    "        self.scheduler.close()\n",
    "        \n",
    "        print('Closing NCS...')\n",
    "        self.fifo_in.destroy()\n",
    "        self.fifo_out.destroy()\n",
    "        self.graph.destroy()\n",
    "        self.device.close()\n",
    "        self.device.destroy()\n",
    "        \n",
    "        print('Closing PiCam...')\n",
    "        self.camera.close()\n",
    "        \n",
    "        print('Closed all successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# IC.__del__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IC = ImageClassifier(graph_file='../Models/MobileNet_SSD_caffe/graph',\n",
    "                     label_file='../Models/MobileNet_SSD_caffe/categories.txt',\n",
    "                     camera_resolution=(1280,720))#(320,240))#(1640, 922)(640,480)(1280,720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "im = IC.take_picture_and_start_inference(debug=True)\n",
    "print('pic:::', time.time() - t)\n",
    "\n",
    "IC.get_inference_result(debug=True)\n",
    "print('total:::', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(im.array.shape)\n",
    "# PIL.Image.fromarray(im.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageClassifier' object has no attribute 'new_results_are_ready'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-5909864ea057>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mIC\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-c5e22282ec55>\u001b[0m in \u001b[0;36mget_results\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_results_are_ready\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_results_are_ready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbb_angles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ImageClassifier' object has no attribute 'new_results_are_ready'"
     ]
    }
   ],
   "source": [
    "IC.get_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import numpy as np\n",
    "# from apscheduler.schedulers.background import BackgroundScheduler\n",
    "\n",
    "# import logging\n",
    "# logging.getLogger('apscheduler.executors.default').setLevel(logging.CRITICAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Stest:\n",
    "#     def __init__(self):\n",
    "#         self.scheduler = BackgroundScheduler()\n",
    "#         self.job1 = self.scheduler.add_job(self.make_data, 'interval', seconds=1, max_instances=1)\n",
    "#         self.job2 = self.scheduler.add_job(self.modify_data, 'interval', seconds=1, max_instances=1)\n",
    "#         self.job3 = self.scheduler.add_job(self.output_data, 'interval', seconds=1, max_instances=1)\n",
    "#         self.num = 1\n",
    "#         self.thing1done = False\n",
    "#         self.thing2done = False\n",
    "#         self.scheduler.start()\n",
    "\n",
    "#     def make_data(self):\n",
    "#         print('thing1 running')\n",
    "#         self.my_arr = np.empty(shape=(3000, 3000))\n",
    "#         self.thing1done = True\n",
    "    \n",
    "#     def modify_data(self):\n",
    "#         if self.thing1done:\n",
    "#             print('modifying data')\n",
    "#             self.my_arr2 = self.my_arr @ self.my_arr\n",
    "#             self.thing1done = False\n",
    "#             self.thing2done = True\n",
    "\n",
    "#     def output_data(self):\n",
    "#         if self.thing2done:\n",
    "#             print('outputting data')\n",
    "#             self.my_arr3 = self.my_arr2 @ self.my_arr2\n",
    "#             self.thing2done = False\n",
    "    \n",
    "#     def close(self):\n",
    "#         self.job1.remove()\n",
    "#         self.job2.remove()\n",
    "#         self.job3.remove()\n",
    "#         self.scheduler.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# s = Stest()\n",
    "# time.sleep(10)\n",
    "# s.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import numpy as np\n",
    "# from apscheduler.schedulers.background import BackgroundScheduler\n",
    "\n",
    "# class Stest:\n",
    "#     def __init__(self):\n",
    "#         self.scheduler = BackgroundScheduler()\n",
    "#         self.job1 = self.scheduler.add_job(self.make_data, 'interval', seconds=1, max_instances=1)\n",
    "#         self.job2 = self.scheduler.add_job(self.modify_data, 'interval', seconds=0.001, max_instances=1)\n",
    "#         self.job3 = self.scheduler.add_job(self.output_data, 'interval', seconds=0.001, max_instances=1)\n",
    "#         self.num = 1\n",
    "#         self.thing1done = False\n",
    "#         self.thing2done = False\n",
    "#         self.scheduler.start()\n",
    "\n",
    "#     def make_data(self):\n",
    "#         print('thing1 running')\n",
    "#         self.my_arr = np.array([self.num, self.num + 1])\n",
    "#         self.num += 1\n",
    "#         self.thing1done = True\n",
    "#         time.sleep(2)\n",
    "    \n",
    "#     def modify_data(self):\n",
    "#         if self.thing1done:\n",
    "#             print('modifying data')\n",
    "#             self.my_arr[0] += 10\n",
    "#             self.thing1done = False\n",
    "#             self.thing2done = True\n",
    "\n",
    "#     def output_data(self):\n",
    "#         if self.thing2done:\n",
    "#             print(self.my_arr)\n",
    "#             self.thing2done = False\n",
    "    \n",
    "#     def close(self):\n",
    "#         self.job1.remove()\n",
    "#         self.job2.remove()\n",
    "#         self.job3.remove()\n",
    "#         self.scheduler.shutdown()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # import the necessary packages\n",
    "# from threading import Thread\n",
    "# import cv2\n",
    "# import imutils\n",
    "\n",
    "# class WebcamVideoStream:\n",
    "#     def __init__(self, src=0):\n",
    "#         # initialize the video camera stream and read the first frame\n",
    "#         # from the stream\n",
    "#         self.camera_resolution=(1280,920)\n",
    "#         self.nn_dim = (300,300)\n",
    "#         self.colourmode = 'bgr'\n",
    "#         self.camera = picamera.PiCamera(resolution=self.camera_resolution, framerate=90)\n",
    "#         self.frame = picamera.array.PiRGBArray(self.camera, size=nn_dim)  #\n",
    "#         self.cont_capture = self.camera.capture_continuous(self.frame, self.colourmode, resize=nn_dim, use_video_port=True)# #use GPU to resize to dim\n",
    "\n",
    "#         # initialize the variable used to indicate if the thread should\n",
    "#         # be stopped\n",
    "#         self.stopped = False\n",
    "\n",
    "#     def start(self):\n",
    "#         # start the thread to read frames from the video stream\n",
    "#         Thread(target=self.update, args=()).start()\n",
    "#         return self\n",
    "\n",
    "#     def update(self):\n",
    "#         # keep looping infinitely until the thread is stopped\n",
    "#         while True:\n",
    "#             # if the thread indicator variable is set, stop the thread\n",
    "#             if self.stopped:\n",
    "#                 return\n",
    "\n",
    "#             # otherwise, read the next frame from the stream\n",
    "#             (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "#     def read(self):\n",
    "#         # return the frame most recently read\n",
    "#         return self.frame\n",
    "\n",
    "#     def stop(self):\n",
    "#         # indicate that the thread should be stopped\n",
    "#         self.stopped = True\n",
    "\n",
    "# vs = WebcamVideoStream(src=0).start()\n",
    "# vs\n",
    "\n",
    "# frame = vs.read()\n",
    "# frame"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
