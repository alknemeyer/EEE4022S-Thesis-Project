{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classifier\n",
    "\n",
    "Contains code for the `ImageClassifer` class, which loads a neural network on the Movidius NCS, takes pictures using a pi cam, passes the (preprocessed) pics through the stick and decodes the result into a bounding box around the category of your choice.\n",
    "\n",
    "Main workflow when importing:\n",
    "1. `import image_classifier`\n",
    "2. `IC = image_classifier.ImageClassifier()`\n",
    "3. Repeat:\n",
    "    - `img_array = IC.take_picture_and_start_inference()`\n",
    "    - `output_dict, bb, inference_time_ms = IC.get_inference_result()`\n",
    "    - `if bb == -1:`\n",
    "        - `    img = PIL.Image.fromarray(img_array)`\n",
    "    - `else:`\n",
    "        - `    (x1, y1), (x2, y2) = bb  # do stuff`\n",
    "\n",
    "---\n",
    "\n",
    "TODO: Much of the code comes from the Movidius GitHub repo, and should be attributed properly!\n",
    "\n",
    "TODO: might need to find a way to avoid resizing the image while preprocessing. Could be compute intensive?\n",
    "\n",
    "TODO: try upping the frame rate of the camera? or setting it to continuously take photos, and only sample when I need it?\n",
    "\n",
    "---\n",
    "\n",
    "I find development using a notebook to be quite a bit easier than developing using a regular python file. Unfortunately, you can't import a `.ipynb` as a module. So, here's the workflow:\n",
    "1. Use this file to understand the code and make changes\n",
    "2. When you want to commit a change, click `Kernal > Restart and Clear Output` to remove your outputs + make the file a bit smaller (shows up as fewer lines in the git commit)\n",
    "3. Run the command `jupyter nbconvert --to=python image_classifier.ipynb` to generate a `.py` file which can be imported as a module. Just make sure to remove your debugging code beforehand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, time\n",
    "import numpy as np\n",
    "import picamera, picamera.array\n",
    "import mvnc.mvncapi as mvnc\n",
    "import PIL.Image, PIL.ImageDraw, PIL.ImageFont"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the NCS device and load the graph file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation.\n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# DIY smart security camera PoC using Raspberry Pi Camera and\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "\n",
    "def open_ncs_device():\n",
    "\n",
    "    # Look for enumerated NCS device(s); quit program if none found.\n",
    "    devices = mvnc.enumerate_devices()\n",
    "    if len(devices) == 0:\n",
    "        print('No NCS devices found')\n",
    "        exit()\n",
    "\n",
    "    # Get a handle to the first enumerated device and open it\n",
    "    device = mvnc.Device(devices[0])\n",
    "    device.open()\n",
    "\n",
    "    return device\n",
    "\n",
    "def load_graph(device, graph_file_name):\n",
    "    # Read the graph file into a buffer\n",
    "    with open(graph_file_name, mode='rb') as f:\n",
    "        blob = f.read()\n",
    "\n",
    "    # Load the graph buffer into the NCS\n",
    "    graph = mvnc.Graph(graph_file_name)\n",
    "    fifo_in, fifo_out = graph.allocate_with_fifos(device, blob)\n",
    "\n",
    "    return graph, fifo_in, fifo_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the image (resizing, scaling, and mean subtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(img, dim, mean, scale):\n",
    "    # Read & resize image [Image size is defined by choosen network, during training]\n",
    "#     img = PIL.Image.fromarray(frame.array)#.resize(dim)\n",
    "#     img = np.array(img, dtype=np.float32)\n",
    "    if img.shape != (dim[0], dim[1], 3):\n",
    "        img = img[:dim[0], :dim[1], :]\n",
    "        print('resizing in preprocess function')\n",
    "\n",
    "    # Mean subtraction & scaling [A common technique used to center the data]\n",
    "    img = (img - np.float32(mean)) * np.float32(scale)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the inference result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_result(graph, shape, fifo_in, fifo_out, confidance_threshold=0.6):\n",
    "    # Get the results from NCS\n",
    "    output, userobj = fifo_out.read_elem()\n",
    "\n",
    "    # Get execution time\n",
    "    inference_time = np.sum(graph.get_option(mvnc.GraphOption.RO_TIME_TAKEN))\n",
    "\n",
    "    # Deserialize the output into a python dictionary\n",
    "    output_dict = deserialize_ssd(output, shape, confidance_threshold)\n",
    "    \n",
    "    return output_dict, inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation. \n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# Utilities to help deserialize the output list from\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "def deserialize_ssd(output, shape, confidance_threshold):\n",
    "    \"\"\"---- Deserialize the output from an SSD based network ----\n",
    "    \n",
    "    @param output The NCS returns a list/array in this structure:\n",
    "        First float16: Number of detections\n",
    "        Next 6 values: Unused\n",
    "        Next consecutive batch of 7 values: Detection values\n",
    "          0: Image ID (always 0)\n",
    "          1: Class ID (index into labels.txt)\n",
    "          2: Detection score\n",
    "          3: Box left coordinate (x1) - scaled value between 0 & 1\n",
    "          4: Box top coordinate (y1) - scaled value between 0 & 1\n",
    "          5: Box right coordinate (x2) - scaled value between 0 & 1\n",
    "          6: Box bottom coordinate (y2) - scaled value between 0 & 1\n",
    "\n",
    "    @return output_dict A Python dictionary with the following keys:\n",
    "        output_dict['num_detections'] = Total number of valid detections\n",
    "        output_dict['detection_classes_<X>'] = Class ID of the detected object\n",
    "        output_dict['detection_scores_<X>'] = Percentage of the confidance\n",
    "        output_dict['detection_boxes_<X>'] = A list of 2 tuples [(x1, y1) (x2, y2)]\n",
    "        Where <X> is a zero-index count of num_detections\n",
    "    \"\"\"\n",
    "\n",
    "    output_dict = {}                # Dictionary where the deserialized output will be stored\n",
    "    height, width, channel = shape  # Extract the original image's shape\n",
    "    output_dict['num_detections'] = int(output[0])  # Total number of detections\n",
    "    num_valid_detections = 0\n",
    "\n",
    "    for detection in range(output_dict['num_detections']):\n",
    "        base_index = 7 + (7 * detection)  # Skip the first 7 values\n",
    "\n",
    "        if (output[base_index + 2] > confidance_threshold):\n",
    "            output_dict['detection_classes_' + str(num_valid_detections)] = int(output[base_index + 1])\n",
    "            output_dict['detection_scores_' + str(num_valid_detections)] = int(output[base_index + 2] * 100)\n",
    "\n",
    "            x = [int(output[base_index + 3] * width), int(output[base_index + 5] * width)]\n",
    "            y = [int(output[base_index + 4] * height), int(output[base_index + 6] * height)]\n",
    "\n",
    "            output_dict['detection_boxes_' + str(num_valid_detections)] = list(zip(y, x))\n",
    "\n",
    "            num_valid_detections += 1\n",
    "\n",
    "    # Update total number of detections to valid detections\n",
    "    output_dict['num_detections'] = int(num_valid_detections)\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for displaying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(output_dict, class_of_interest, frame, labels, capture_screenshots=False):\n",
    "    # Print the results (each image/frame may have multiple objects)\n",
    "    for i in range(output_dict['num_detections']):\n",
    "        \n",
    "        if (output_dict.get('detection_classes_' + str(i)) == class_of_interest):\n",
    "            \n",
    "            # Extract top-left & bottom-right coordinates of detected objects\n",
    "            (y1, x1) = output_dict.get('detection_boxes_' + str(i))[0]\n",
    "            (y2, x2) = output_dict.get('detection_boxes_' + str(i))[1]\n",
    "\n",
    "            # Prep string to overlay on the image\n",
    "            display_str = (labels[output_dict.get('detection_classes_%i' % i)]\n",
    "                           + ': %s%%' % output_dict.get('detection_scores_%i' % i))\n",
    "\n",
    "            # Overlay bounding boxes, detection class and scores\n",
    "            frame = draw_bounding_box( \n",
    "                        y1, x1, y2, x2,\n",
    "                        frame, display_str=display_str)\n",
    "\n",
    "    if capture_screenshots:\n",
    "        img = PIL.Image.fromarray(frame)\n",
    "        img.save('captures/photo_%s.jpg' % cur_time)\n",
    "\n",
    "    # If a display is available, show image on which inference was performed\n",
    "    if 'DISPLAY' in os.environ:\n",
    "        img.show()\n",
    "\n",
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation. \n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# Utilities to help visualize the output from\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "def draw_bounding_box(y1, x1, y2, x2, \n",
    "                      img, \n",
    "                      thickness=4, \n",
    "                      color=(255, 255, 0),\n",
    "                      display_str=()):\n",
    "    \"\"\" draw a bounding box on an image to help visualise the nn output\n",
    "    \n",
    "    Inputs\n",
    "        (x1, y1)  = Top left corner of the bounding box\n",
    "        (x2, y2)  = Bottom right corner of the bounding box\n",
    "        img       = Image/frame represented as numpy array\n",
    "        thickness = Thickness of the bounding box's outline\n",
    "        color     = Color of the bounding box's outline\n",
    "    \"\"\"\n",
    "    img = PIL.Image.fromarray(img)\n",
    "    draw = PIL.ImageDraw.Draw(img)\n",
    "\n",
    "    for x in range(0, thickness):\n",
    "        draw.rectangle([(x1-x, y1-x), (x2-x, y2-x)], outline=color)\n",
    "\n",
    "    font = PIL.ImageFont.load_default()\n",
    "    draw.text((x1, y1), display_str, font=font)\n",
    "\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_to_angle(pixel, img_size, cam_angle_deg):\n",
    "    \"\"\" convert a pixel value to an angle in degrees\n",
    "    inputs:\n",
    "        pixel:              a value from 0 to img_size\n",
    "        img_size:           the total number of pixels along that axis of the image\n",
    "        cam_angle_deg:      the angular width of camera in degrees\n",
    "        \n",
    "    output:\n",
    "        angle:      0deg = when pixel is directly ahead, positive/negative = right/left of center\n",
    "    \"\"\"\n",
    "    norm_pixel = (2*pixel/img_size) - 1  # now in range [-1, 1]\n",
    "    angle = np.arctan(norm_pixel * np.tan(np.deg2rad(cam_angle_deg/2)))\n",
    "    return np.rad2deg(angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ImageClassifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier():\n",
    "    \"\"\" class to make the whole process of taking pictures etc easy\n",
    "    \n",
    "    methods:\n",
    "        ImageClassifier.__init__(...)\n",
    "        ImageClassifier.take_picture_and_start_inference()\n",
    "        ImageClassifier.get_inference_result()\n",
    "        ImageClassifier.__del__()\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 graph_file='graph',\n",
    "                 label_file='categories.txt',  # must correspond to the specific network\n",
    "                 mean=(127.5, 127.5, 127.5),   # depends on the colourmode\n",
    "                 scale=0.00789,                # = 1/127\n",
    "                 nn_dim=(300, 300),            # (width, height)\n",
    "                 colourmode='rgb',\n",
    "                 camera_resolution=(1640, 922), # (width, height)\n",
    "                 camera_FOV=(62.2, 48.8),      # (width, height)\n",
    "                 class_of_interest='person'):  # could also be 'dog', 'cat', etc (see categories.txt file)\n",
    "        self.mean = mean\n",
    "        self.scale = scale\n",
    "        self.dim = nn_dim\n",
    "        self.colourmode = colourmode\n",
    "        self.camera_resolution = camera_resolution\n",
    "        self.camera_FOV = camera_FOV\n",
    "        \n",
    "        # Load the labels file and get the index (=ID) of the class of interest\n",
    "        self.labels = [line.rstrip('\\n') for line in open(label_file) if line != 'classes\\n']\n",
    "        self.class_of_interest = self.labels.index(class_of_interest)\n",
    "\n",
    "        # sort out the NCS stuff\n",
    "        self.device = open_ncs_device()\n",
    "        self.graph, self.fifo_in, self.fifo_out = load_graph(self.device, graph_file)\n",
    "        \n",
    "        # open the camera and start streaming\n",
    "        self.camera = picamera.PiCamera(resolution=self.camera_resolution, framerate=90)\n",
    "        self.frame = picamera.array.PiRGBArray(self.camera, size=nn_dim)  #\n",
    "        self.cont_capture = self.camera.capture_continuous(self.frame, self.colourmode, resize=nn_dim, use_video_port=True)# #use GPU to resize to dim\n",
    "\n",
    "        \n",
    "    def take_picture_and_start_inference(self, debug=False):\n",
    "        Thread(target=self._take_pic, args=()).start()\n",
    "        Thread(target=self._preprocess_and_queue, args=()).start()\n",
    "    \n",
    "    def _take_pic(self):\n",
    "        while True:\n",
    "            \"\"\" takes a picture and starts the inference, but doesn't wait for the result \"\"\"\n",
    "            debug=False\n",
    "            if debug: t = time.time()\n",
    "            self.frame.seek(0)\n",
    "            self.frame.truncate(0)\n",
    "            next(self.cont_capture)\n",
    "            if debug: print('photo capture time = %d ms' % ((time.time() - t)*1000))\n",
    "    \n",
    "    def _preprocess_and_queue(self):\n",
    "        while True:\n",
    "            debug = False\n",
    "            if debug: t = time.time()\n",
    "            preprocessed_img = pre_process_image(self.frame, self.dim, self.mean, self.scale)\n",
    "            if debug: print('preprocessing time = %d ms' % ((time.time() - t)*1000))\n",
    "\n",
    "            # load the image as a floating point array\n",
    "            if debug: t = time.time()\n",
    "            self.graph.queue_inference_with_fifo_elem(self.fifo_in, self.fifo_out, preprocessed_img, None)\n",
    "            if debug: print('queue for inference time = %d ms' % ((time.time() - t)*1000))\n",
    "        \n",
    "        #return self.frame\n",
    "\n",
    "\n",
    "    def get_inference_result(self, show_image=False, debug=False):\n",
    "        if debug: t = time.time()\n",
    "        output_dict, inference_time_ms = get_inference_result(self.graph,\n",
    "                                                           self.frame.array.shape,\n",
    "                                                           self.fifo_in,\n",
    "                                                           self.fifo_out)\n",
    "        if debug: print('get inference result = %d ms' % ((time.time() - t)*1000))\n",
    "        \n",
    "        if 'DISPLAY' in os.environ and show_image is True:\n",
    "            display_image(output_dict, self.class_of_interest, self.frame, self.labels)\n",
    "        \n",
    "        for i in range(output_dict['num_detections']):\n",
    "            if (output_dict.get('detection_classes_%i' % i) == self.class_of_interest):\n",
    "                (y1, x1) = output_dict.get('detection_boxes_' + str(i))[0]\n",
    "                (y2, x2) = output_dict.get('detection_boxes_' + str(i))[1]\n",
    "                bb = (x1, y1), (x2, y2)\n",
    "                \n",
    "                w, h = self.camera_resolution\n",
    "                cam_width = self.camera_FOV[0]\n",
    "                cam_height = self.camera_FOV[1]\n",
    "                x1_angle = pixel_to_angle(x1, w, cam_width)\n",
    "                x2_angle = pixel_to_angle(x2, w, cam_width)\n",
    "                y1_angle = pixel_to_angle(y1, h, cam_height)\n",
    "                y2_angle = pixel_to_angle(y2, h, cam_height)\n",
    "                bb_angles = ((x1_angle, y1_angle), (x2_angle, y2_angle))\n",
    "                \n",
    "                return output_dict, bb, bb_angles, inference_time_ms\n",
    "\n",
    "        # couldn't find the class of interest\n",
    "        return output_dict, -1, -1, inference_time_ms\n",
    "\n",
    "    \n",
    "    def __del__(self):\n",
    "        print('Closing NCS...')\n",
    "        self.fifo_in.destroy()\n",
    "        self.fifo_out.destroy()\n",
    "        self.graph.destroy()\n",
    "        self.device.close()\n",
    "        self.device.destroy()\n",
    "        \n",
    "        print('Closing PiCam...')\n",
    "        self.camera.close()\n",
    "        \n",
    "        print('Closed both successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IC.__del__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IC = ImageClassifier(graph_file='../Models/MobileNet_SSD_caffe/graph',\n",
    "                     label_file='../Models/MobileNet_SSD_caffe/categories.txt',\n",
    "                     camera_resolution=(320,240))#(1640, 922)(640,480)(1280,720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t = time.time()\n",
    "im = IC.take_picture_and_start_inference(debug=True)\n",
    "print('pic:::', time.time() - t)\n",
    "\n",
    "IC.get_inference_result(debug=True)\n",
    "print('total:::', time.time() - t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(im.array.shape)\n",
    "PIL.Image.fromarray(im.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IC.camera.sensor_mode = 5\n",
    "IC.camera.resolution = (300, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(IC.camera.sensor_mode)\n",
    "print(IC.camera.resolution)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from threading import Thread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from threading import Thread\n",
    "import cv2\n",
    "import imutils\n",
    "\n",
    "class WebcamVideoStream:\n",
    "    def __init__(self, src=0):\n",
    "        # initialize the video camera stream and read the first frame\n",
    "        # from the stream\n",
    "        self.camera_resolution=(1280,920)\n",
    "        self.nn_dim = (300,300)\n",
    "        self.colourmode = 'bgr'\n",
    "        self.camera = picamera.PiCamera(resolution=self.camera_resolution, framerate=90)\n",
    "        self.frame = picamera.array.PiRGBArray(self.camera, size=nn_dim)  #\n",
    "        self.cont_capture = self.camera.capture_continuous(self.frame, self.colourmode, resize=nn_dim, use_video_port=True)# #use GPU to resize to dim\n",
    "\n",
    "        # initialize the variable used to indicate if the thread should\n",
    "        # be stopped\n",
    "        self.stopped = False\n",
    "\n",
    "    def start(self):\n",
    "        # start the thread to read frames from the video stream\n",
    "        Thread(target=self.update, args=()).start()\n",
    "        return self\n",
    "\n",
    "    def update(self):\n",
    "        # keep looping infinitely until the thread is stopped\n",
    "        while True:\n",
    "            # if the thread indicator variable is set, stop the thread\n",
    "            if self.stopped:\n",
    "                return\n",
    "\n",
    "            # otherwise, read the next frame from the stream\n",
    "            (self.grabbed, self.frame) = self.stream.read()\n",
    "\n",
    "    def read(self):\n",
    "        # return the frame most recently read\n",
    "        return self.frame\n",
    "\n",
    "    def stop(self):\n",
    "        # indicate that the thread should be stopped\n",
    "        self.stopped = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = WebcamVideoStream(src=0).start()\n",
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = vs.read()\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = imutils.resize(frame, width=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.VideoCapture(0).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "from apscheduler.schedulers.background import BackgroundScheduler\n",
    "\n",
    "class Stest:\n",
    "    def __init__(self):\n",
    "\n",
    "        self.scheduler = BackgroundScheduler()\n",
    "        self.job = self.scheduler.add_job(self.toggle_camera, 'interval', seconds=0.25, max_instances=2)\n",
    "        self.camera_state = True\n",
    "        self.heart_beat = 0\n",
    "        self.heart_beat2 = 0\n",
    "        self.scheduler.start()\n",
    "\n",
    "        self.waste_time()\n",
    "\n",
    "    def camera(self, mode):\n",
    "        print('mode = : ' + str(mode))\n",
    "        if mode:\n",
    "            while True:\n",
    "                # print('heart_beat: ' + str(self.heart_beat))\n",
    "                self.heart_beat += 1\n",
    "\n",
    "    def toggle_camera(self):\n",
    "        print('camera_state = ' + str(self.camera_state))\n",
    "        self.camera_state = not self.camera_state\n",
    "\n",
    "    def waste_time(self):\n",
    "        while True:\n",
    "            print('wasting time: ' + str(self.heart_beat2))\n",
    "            self.heart_beat2 += 1\n",
    "            time.sleep(1)\n",
    "\n",
    "\n",
    "s = Stest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# IC = ImageClassifier(graph_file='../Models/MobileNet_SSD_caffe/graph',\n",
    "#                      label_file='../Models/MobileNet_SSD_caffe/categories.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# yaw_arr = []\n",
    "# pitch_arr = []\n",
    "# inference_time_arr = []\n",
    "# loop_time_arr = []\n",
    "# i_arr = []\n",
    "# t = time.time()\n",
    "\n",
    "# # time.sleep(5)\n",
    "\n",
    "# for i in range(30):\n",
    "#     img_array = IC.take_picture_and_start_inference()\n",
    "#     output_dict, bb, bb_angles, inference_time_ms = IC.get_inference_result()\n",
    "    \n",
    "#     inference_time_arr.append(inference_time_ms)\n",
    "\n",
    "#     loop_time_arr.append(time.time() - t)\n",
    "    \n",
    "#     if bb_angles == -1:\n",
    "#         i_arr.append(0)\n",
    "#     else:\n",
    "#         (phi_x1, phi_y1), (phi_x2, phi_y2) = bb_angles\n",
    "#         phi_yaw = (phi_x1 + phi_x2)/2\n",
    "#         phi_pitch = (phi_y1 + phi_y2)/2\n",
    "#         yaw_arr.append(phi_yaw)\n",
    "#         pitch_arr.append(phi_pitch)\n",
    "\n",
    "#         i_arr.append(1)\n",
    "    \n",
    "#     t = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(yaw_arr, label='yaw centroid [deg]')\n",
    "# plt.plot(pitch_arr, label='pitch centroid [deg]')\n",
    "# plt.plot(i_arr, label='1 = object detected')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(inference_time_arr, label='NCS time [ms]')\n",
    "# plt.plot([1000*t for t in loop_time_arr], label='loop time [ms]')\n",
    "# plt.plot([1000*t_loop - t_inf for t_loop, t_inf in zip(loop_time_arr, inference_time_arr)], label='other time stuff')\n",
    "# plt.stem([i*100 for i in i_arr], label='1 = object detected')\n",
    "# plt.legend(loc='lower right')\n",
    "# plt.grid()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del IC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
