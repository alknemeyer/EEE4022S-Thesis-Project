{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classifier\n",
    "\n",
    "Contains code for the `ImageClassifer` class\n",
    "\n",
    "Much of the code comes from the Movidius GitHub repo\n",
    "\n",
    "I find development using a notebook to be quite a bit easier than developing using a regular python file. Unfortunately, you can't import a `.ipynb` as a module. So, here's the workflow:\n",
    "1. Use this file to understand the code and make changes\n",
    "2. Click `Kernal > Restart and Clear Output` to remove your outputs and make the file a bit smaller (shows up as fewer lines in the git commit)\n",
    "3. Uncomment and run the line below to generate a `.py` file which can be imported as a module. Just make sure to remove your debugging code beforehand!\n",
    "\n",
    "Main workflow when importing:\n",
    "1. `import image_classifier`\n",
    "2. `IC = image_classifier.ImageClassifier()`\n",
    "3. Repeat:\n",
    "    1. `img_array = IC.take_picture_and_start_inference()`\n",
    "    2. `output_dict, bb, inference_time_ms = IC.get_inference_result()`\n",
    "    3. `if bb == -1:`\n",
    "       `    img = PIL.Image.fromarray(img_array)`\n",
    "       `else:`\n",
    "       `    (x1, y1), (x2, y2) = bb  # do stuff`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a .py file, which can be imported as a module\n",
    "# !jupyter nbconvert --to=python image_classifier.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation.\n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# DIY smart security camera PoC using Raspberry Pi Camera and\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import picamera\n",
    "import picamera.array\n",
    "import mvnc.mvncapi as mvnc\n",
    "import PIL.Image\n",
    "import PIL.ImageDraw\n",
    "import PIL.ImageFont\n",
    "\n",
    "from time import localtime, strftime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open the NCS device and load the graph file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_ncs_device():\n",
    "\n",
    "    # Look for enumerated NCS device(s); quit program if none found.\n",
    "    devices = mvnc.enumerate_devices()\n",
    "    if len(devices) == 0:\n",
    "        print('No NCS devices found')\n",
    "        quit()\n",
    "\n",
    "    # Get a handle to the first enumerated device and open it\n",
    "    device = mvnc.Device(devices[0])\n",
    "    device.open()\n",
    "\n",
    "    return device\n",
    "\n",
    "def load_graph(device, graph_file_name):\n",
    "    # Read the graph file into a buffer\n",
    "    with open(graph_file_name, mode='rb') as f:\n",
    "        blob = f.read()\n",
    "\n",
    "    # Load the graph buffer into the NCS\n",
    "    graph = mvnc.Graph(graph_file_name)\n",
    "    fifo_in, fifo_out = graph.allocate_with_fifos(device, blob)\n",
    "\n",
    "    return graph, fifo_in, fifo_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process the image (resizing, scaling, and mean subtraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(frame, dim, mean, scale):\n",
    "    # Read & resize image\n",
    "    # [Image size is defined by choosen network, during training]\n",
    "    img = PIL.Image.fromarray(frame.array).resize(dim)\n",
    "    img = np.array(img, dtype=np.float32)\n",
    "\n",
    "    # Mean subtraction & scaling [A common technique used to center the data]\n",
    "    img = (img - np.float32(mean)) * np.float32(scale)\n",
    "\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the inference result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_inference_result(graph, shape, fifo_in, fifo_out):\n",
    "    # Get the results from NCS\n",
    "    output, userobj = fifo_out.read_elem()\n",
    "\n",
    "    # Get execution time\n",
    "    inference_time = np.sum(graph.get_option(mvnc.GraphOption.RO_TIME_TAKEN))\n",
    "\n",
    "    # Deserialize the output into a python dictionary\n",
    "    output_dict = ssd(output, shape)\n",
    "    \n",
    "    return output_dict, inference_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation. \n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# Utilities to help deserialize the output list from\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "def ssd(output, shape, confidance_threshold=0.6):\n",
    "    \"\"\"---- Deserialize the output from an SSD based network ----\n",
    "    \n",
    "    @param output The NCS returns a list/array in this structure:\n",
    "        First float16: Number of detections\n",
    "        Next 6 values: Unused\n",
    "        Next consecutive batch of 7 values: Detection values\n",
    "          0: Image ID (always 0)\n",
    "          1: Class ID (index into labels.txt)\n",
    "          2: Detection score\n",
    "          3: Box left coordinate (x1) - scaled value between 0 & 1\n",
    "          4: Box top coordinate (y1) - scaled value between 0 & 1\n",
    "          5: Box right coordinate (x2) - scaled value between 0 & 1\n",
    "          6: Box bottom coordinate (y2) - scaled value between 0 & 1\n",
    "\n",
    "    @return output_dict A Python dictionary with the following keys:\n",
    "        output_dict['num_detections'] = Total number of valid detections\n",
    "        output_dict['detection_classes_<X>'] = Class ID of the detected object\n",
    "        output_dict['detection_scores_<X>'] = Percentage of the confidance\n",
    "        output_dict['detection_boxes_<X>'] = A list of 2 tuples [(x1, y1) (x2, y2)]\n",
    "        Where <X> is a zero-index count of num_detections\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary where the deserialized output will be stored\n",
    "    output_dict = {}\n",
    "\n",
    "    # Extract the original image's shape\n",
    "    height, width, channel = shape\n",
    "\n",
    "    # Total number of detections\n",
    "    output_dict['num_detections'] = int(output[0])\n",
    "\n",
    "    # Variable to track number of valid detections\n",
    "    valid_detections = 0\n",
    "\n",
    "    for detection in range(output_dict['num_detections']):\n",
    "\n",
    "        # Skip the first 7 values, and point to the next batch of 7 values\n",
    "        base_index = 7 + (7 * detection)\n",
    "\n",
    "        # Record only those detections whose confidance meets our threshold\n",
    "        if(output[base_index + 2] > confidance_threshold):\n",
    "\n",
    "            output_dict['detection_classes_' + str(valid_detections)] = int(output[base_index + 1])\n",
    "            output_dict['detection_scores_' + str(valid_detections)] = int(output[base_index + 2] * 100)\n",
    "\n",
    "            x = [int(output[base_index + 3] * width), int(output[base_index + 5] * width)]\n",
    "            y = [int(output[base_index + 4] * height), int(output[base_index + 6] * height)]\n",
    "\n",
    "            output_dict['detection_boxes_' + str(valid_detections)] = list(zip(y, x))\n",
    "\n",
    "            valid_detections += 1\n",
    "\n",
    "    # Update total number of detections to valid detections\n",
    "    output_dict['num_detections'] = int(valid_detections)\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for displaying images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_image(output_dict, class_of_interest, frame, labels, capture_screenshots=False):\n",
    "    # Print the results (each image/frame may have multiple objects)\n",
    "    for i in range(0, output_dict['num_detections']):\n",
    "        \n",
    "        # Filter a specific class/category\n",
    "        if (output_dict.get('detection_classes_' + str(i)) == class_of_interest):\n",
    "            \n",
    "            # Extract top-left & bottom-right coordinates of detected objects\n",
    "            (y1, x1) = output_dict.get('detection_boxes_' + str(i))[0]\n",
    "            (y2, x2) = output_dict.get('detection_boxes_' + str(i))[1]\n",
    "\n",
    "            # Prep string to overlay on the image\n",
    "            display_str = (\n",
    "                labels[output_dict.get('detection_classes_%i' % i)]\n",
    "                + ': %s%%' % output_dict.get('detection_scores_%i' % i))\n",
    "\n",
    "            # Overlay bounding boxes, detection class and scores\n",
    "            frame = draw_bounding_box( \n",
    "                        y1, x1, y2, x2,\n",
    "                        frame,\n",
    "                        thickness=4,\n",
    "                        color=(255, 255, 0),\n",
    "                        display_str=display_str)\n",
    "\n",
    "    if capture_screenshots:\n",
    "        img = PIL.Image.fromarray(frame)\n",
    "        img.save('captures/photo_%s.jpg' % cur_time)\n",
    "\n",
    "    # If a display is available, show image on which inference was performed\n",
    "    if 'DISPLAY' in os.environ:\n",
    "        img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation. \n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# Utilities to help visualize the output from\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "\n",
    "def draw_bounding_box(y1, x1, y2, x2, \n",
    "                      img, \n",
    "                      thickness=4, \n",
    "                      color=(255, 255, 0),\n",
    "                      display_str=()):\n",
    "    \"\"\" draw a bounding box on an image to help visualise the nn output\n",
    "    \n",
    "    Inputs\n",
    "        (x1, y1)  = Top left corner of the bounding box\n",
    "        (x2, y2)  = Bottom right corner of the bounding box\n",
    "        img       = Image/frame represented as numpy array\n",
    "        thickness = Thickness of the bounding box's outline\n",
    "        color     = Color of the bounding box's outline\n",
    "    \"\"\"\n",
    "\n",
    "    img = PIL.Image.fromarray(img)\n",
    "    draw = PIL.ImageDraw.Draw(img)\n",
    "\n",
    "    for x in range(0, thickness):\n",
    "        draw.rectangle([(x1-x, y1-x), (x2-x, y2-x)], outline=color)\n",
    "\n",
    "    font = PIL.ImageFont.load_default()\n",
    "    draw.text((x1, y1), display_str, font=font)\n",
    "\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The ImageClassifier class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageClassifier():\n",
    "    \"\"\" class to make the whole process of taking pictures etc easy\n",
    "    \n",
    "    methods:\n",
    "        ImageClassifier.__init__(...)\n",
    "        ImageClassifier.take_picture_and_start_inference()\n",
    "        ImageClassifier.get_inference_result()\n",
    "        ImageClassifier.close_ncs_device()        \n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 graph_file='graph',\n",
    "                 label_file='categories.txt',\n",
    "                 mean=[127.5, 127.5, 127.5],\n",
    "                 scale=0.00789, # 1/127\n",
    "                 dim=[300, 300],\n",
    "                 colourmode='rgb',\n",
    "                 camera_resolution=(640, 480),\n",
    "                 class_of_interest='person'):  # could also be 'dog', 'cat', etc (see categories.txt file)\n",
    "        self.mean = mean\n",
    "        self.scale = scale\n",
    "        self.dim = dim\n",
    "        self.colourmode = colourmode\n",
    "        self.camera_resolution = camera_resolution\n",
    "        \n",
    "        # Load the labels file and get the index (=ID) of the class of interest\n",
    "        self.labels = [line.rstrip('\\n') for line in open(label_file) if line != 'classes\\n']\n",
    "        self.class_of_interest = self.labels.index(class_of_interest)\n",
    "\n",
    "        # sort out the NCS stuff\n",
    "        self.device = open_ncs_device()\n",
    "        self.graph, self.fifo_in, self.fifo_out = load_graph(self.device, graph_file)\n",
    "        \n",
    "        \n",
    "    def take_picture_and_start_inference(self):\n",
    "        \"\"\" takes a picture and starts the inference, but doesn't wait for a \"\"\"\n",
    "        with picamera.PiCamera(resolution=self.camera_resolution) as camera:\n",
    "            self.frame = picamera.array.PiRGBArray(camera)\n",
    "            camera.capture(self.frame, self.colourmode)\n",
    "\n",
    "            preprocessed_img = pre_process_image(self.frame, self.dim, self.mean, self.scale)\n",
    "\n",
    "            # Load the image as a half-precision floating point array\n",
    "            self.graph.queue_inference_with_fifo_elem(self.fifo_in, self.fifo_out, preprocessed_img, None)\n",
    "\n",
    "            return self.frame.array\n",
    "\n",
    "\n",
    "    def get_inference_result(self):\n",
    "        output_dict, inference_time_ms = get_inference_result(self.graph,\n",
    "                                                           self.frame.array.shape,\n",
    "                                                           self.fifo_in,\n",
    "                                                           self.fifo_out)\n",
    "        \n",
    "#         if 'DISPLAY' in os.environ:\n",
    "#             display_image(output_dict, self.class_of_interest, self.frame, self.labels)\n",
    "        \n",
    "        for i in range(output_dict['num_detections']):\n",
    "            if (output_dict.get('detection_classes_%i' % i) == self.class_of_interest):\n",
    "                (y1, x1) = output_dict.get('detection_boxes_' + str(i))[0]\n",
    "                (y2, x2) = output_dict.get('detection_boxes_' + str(i))[1]\n",
    "#                 w, h = self.camera_resolution\n",
    "#                 bb = (x1/w, y1/h), (x2/w, y2/h)  # TODO: scaling??\n",
    "                bb = (x1, y1), (x2, y2)\n",
    "                return output_dict, bb, inference_time_ms\n",
    "        \n",
    "        return output_dict, -1, inference_time_ms\n",
    "        \n",
    "        # couldn't find the class of interest\n",
    "#         return -1, -1, -1\n",
    "            \n",
    "#         output_dict['detection_classes_<X>'] = Class ID of the detected object\n",
    "#         output_dict['detection_scores_<X>'] = Percentage of the confidance\n",
    "#         output_dict['detection_boxes_<X>'] = A list of 2 tuples [(x1, y1) (x2, y2)]\n",
    "\n",
    "    \n",
    "    def __del__(self):\n",
    "        self.fifo_in.destroy()\n",
    "        self.fifo_out.destroy()\n",
    "\n",
    "        self.graph.destroy()\n",
    "\n",
    "        self.device.close()\n",
    "        self.device.destroy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# IC = ImageClassifier(graph_file='../Models/MobileNet_SSD_caffe/graph',\n",
    "#                      label_file='../Models/MobileNet_SSD_caffe/categories.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# img_array = IC.take_picture_and_start_inference()\n",
    "# output_dict, bb, inference_time_ms = IC.get_inference_result()\n",
    "\n",
    "# print(output_dict)\n",
    "# print(bb)\n",
    "# print(inference_time_ms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if bb == -1:\n",
    "#     img = PIL.Image.fromarray(img_array)\n",
    "# else:\n",
    "#     (x1, y1), (x2, y2) = bb\n",
    "#     img = PIL.Image.fromarray(img_array)\n",
    "#     img = PIL.Image.fromarray(draw_bounding_box(y1, x1, y2, x2, img_array))\n",
    "\n",
    "# img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# del IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# timeit.timeit(my_func, number=10)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def my_func():\n",
    "#     with picamera.PiCamera(resolution=(300,300)) as camera:\n",
    "#         frame = picamera.array.PiRGBArray(camera)\n",
    "#         camera.capture(frame, 'rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_func()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
