{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, os, time, matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add a legend and grid to a `matplotlib.pyplot` plot, and resize it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_util(_plt, height_inch=5):\n",
    "    _plt.legend()\n",
    "    _plt.grid()\n",
    "    fig = _plt.gcf()\n",
    "    fig.set_size_inches(18.5, height_inch, forward=True)\n",
    "    _plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the output from an `SSD` neural network into an `output_dict`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation. \n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# Utilities to help deserialize the output list from\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "def deserialize_ssd(output, shape, confidance_threshold):\n",
    "    \"\"\"---- Deserialize the output from an SSD based network ----\n",
    "    \n",
    "    @param output The NCS returns a list/array in this structure:\n",
    "        First float16: Number of detections\n",
    "        Next 6 values: Unused\n",
    "        Next consecutive batch of 7 values: Detection values\n",
    "          0: Image ID (always 0)\n",
    "          1: Class ID (index into labels.txt)\n",
    "          2: Detection score\n",
    "          3: Box left coordinate (x1) - scaled value between 0 & 1\n",
    "          4: Box top coordinate (y1) - scaled value between 0 & 1\n",
    "          5: Box right coordinate (x2) - scaled value between 0 & 1\n",
    "          6: Box bottom coordinate (y2) - scaled value between 0 & 1\n",
    "\n",
    "    @return output_dict A Python dictionary with the following keys:\n",
    "        output_dict['num_detections'] = Total number of valid detections\n",
    "        output_dict['detection_classes_<X>'] = Class ID of the detected object\n",
    "        output_dict['detection_scores_<X>'] = Percentage of the confidance\n",
    "        output_dict['detection_boxes_<X>'] = A list of 2 tuples [(x1, y1) (x2, y2)]\n",
    "        Where <X> is a zero-index count of num_detections\n",
    "    \"\"\"\n",
    "\n",
    "    output_dict = {}                # Dictionary where the deserialized output will be stored\n",
    "    height, width = shape           # Extract the original image's shape\n",
    "    channel = 3\n",
    "    output_dict['num_detections'] = int(output[0])  # Total number of detections\n",
    "    num_valid_detections = 0\n",
    "\n",
    "    for detection in range(output_dict['num_detections']):\n",
    "        base_index = 7 + (7 * detection)  # Skip the first 7 values\n",
    "\n",
    "        if (output[base_index + 2] > confidance_threshold):\n",
    "            output_dict['detection_classes_' + str(num_valid_detections)] = int(output[base_index + 1])\n",
    "            output_dict['detection_scores_' + str(num_valid_detections)] = int(output[base_index + 2] * 100)\n",
    "\n",
    "            x = [int(output[base_index + 3] * width), int(output[base_index + 5] * width)]\n",
    "            y = [int(output[base_index + 4] * height), int(output[base_index + 6] * height)]\n",
    "\n",
    "            output_dict['detection_boxes_' + str(num_valid_detections)] = list(zip(y, x))\n",
    "\n",
    "            num_valid_detections += 1\n",
    "\n",
    "    # Update total number of detections to valid detections\n",
    "    output_dict['num_detections'] = int(num_valid_detections)\n",
    "\n",
    "    return output_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert the `output_dict` to tuples of bounding boxes (pixels and angles angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_dict_to_bb_and_angles(output_dict, class_of_interest, camera_resolution, camera_FOV):\n",
    "    for i in range(output_dict['num_detections']):\n",
    "        if (output_dict.get('detection_classes_%i' % i) == class_of_interest):\n",
    "            (y1, x1) = output_dict.get('detection_boxes_' + str(i))[0]\n",
    "            (y2, x2) = output_dict.get('detection_boxes_' + str(i))[1]\n",
    "            bb = (x1, y1), (x2, y2)\n",
    "\n",
    "            w, h = camera_resolution\n",
    "            cam_width = camera_FOV[0]\n",
    "            cam_height = camera_FOV[1]\n",
    "            x1_angle = pixel_to_angle(x1, w, cam_width)\n",
    "            x2_angle = pixel_to_angle(x2, w, cam_width)\n",
    "            y1_angle = pixel_to_angle(y1, h, cam_height)\n",
    "            y2_angle = pixel_to_angle(y2, h, cam_height)\n",
    "            bb_angles = ((x1_angle, y1_angle), (x2_angle, y2_angle))\n",
    "\n",
    "            return bb, bb_angles\n",
    "    return -1, -1\n",
    "\n",
    "def pixel_to_angle(pixel, img_size, cam_angle_deg):\n",
    "    \"\"\" convert a pixel value to an angle in degrees\n",
    "    inputs:\n",
    "        pixel:              a value from 0 to img_size\n",
    "        img_size:           the total number of pixels along that axis of the image\n",
    "        cam_angle_deg:      the angular width of camera in degrees\n",
    "        \n",
    "    output:\n",
    "        angle:      0deg = when pixel is directly ahead, positive/negative = right/left of center\n",
    "    \"\"\"\n",
    "    norm_pixel = (2*pixel/img_size) - 1  # now in range [-1, 1]\n",
    "    angle = np.arctan(norm_pixel * np.tan(np.deg2rad(cam_angle_deg/2)))\n",
    "    return np.rad2deg(angle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overlay data from `output_dict` onto an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL.Image, PIL.ImageDraw, PIL.ImageFont\n",
    "\n",
    "def display_image(output_dict, class_of_interest, frame, labels, capture_screenshots=False):\n",
    "    # Print the results (each image/frame may have multiple objects)\n",
    "    for i in range(output_dict['num_detections']):\n",
    "        \n",
    "        if class_of_interest =='all' or (output_dict.get('detection_classes_' + str(i)) == class_of_interest):\n",
    "            \n",
    "            # Extract top-left & bottom-right coordinates of detected objects\n",
    "            (y1, x1) = output_dict.get('detection_boxes_' + str(i))[0]\n",
    "            (y2, x2) = output_dict.get('detection_boxes_' + str(i))[1]\n",
    "\n",
    "            # Prep string to overlay on the image\n",
    "            display_str = (labels[output_dict.get('detection_classes_%i' % i)]\n",
    "                           + ': %s%%' % output_dict.get('detection_scores_%i' % i))\n",
    "\n",
    "            # Overlay bounding boxes, detection class and scores\n",
    "            frame = draw_bounding_box( \n",
    "                        y1, x1, y2, x2,\n",
    "                        frame, display_str=display_str)\n",
    "\n",
    "    if capture_screenshots:\n",
    "        img = PIL.Image.fromarray(frame)\n",
    "        img.save('captures/photo_%s.jpg' % cur_time)\n",
    "\n",
    "    # If a display is available, show image on which inference was performed\n",
    "    if 'DISPLAY' in os.environ:\n",
    "        img.show()\n",
    "    \n",
    "    return frame\n",
    "\n",
    "# ****************************************************************************\n",
    "# Copyright(c) 2017 Intel Corporation. \n",
    "# License: MIT See LICENSE file in root directory.\n",
    "# ****************************************************************************\n",
    "\n",
    "# Utilities to help visualize the output from\n",
    "# Intel® Movidius™ Neural Compute Stick (NCS)\n",
    "def draw_bounding_box(y1, x1, y2, x2, \n",
    "                      img, \n",
    "                      thickness=4, \n",
    "                      color=(255, 255, 0),\n",
    "                      display_str=()):\n",
    "    \"\"\" draw a bounding box on an image to help visualise the nn output\n",
    "    \n",
    "    Inputs\n",
    "        (x1, y1)  = Top left corner of the bounding box\n",
    "        (x2, y2)  = Bottom right corner of the bounding box\n",
    "        img       = Image/frame represented as numpy array\n",
    "        thickness = Thickness of the bounding box's outline\n",
    "        color     = Color of the bounding box's outline\n",
    "    \"\"\"\n",
    "    img = PIL.Image.fromarray(img)\n",
    "    draw = PIL.ImageDraw.Draw(img)\n",
    "\n",
    "    for x in range(0, thickness):\n",
    "        draw.rectangle([(x1-x, y1-x), (x2-x, y2-x)], outline=color)\n",
    "\n",
    "    font = PIL.ImageFont.load_default()\n",
    "    draw.text((x1, y1), display_str, font=font)\n",
    "\n",
    "    return np.array(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logger to keep track of `EKF` angles, and plot afterwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentLogger():\n",
    "    def __init__(self):\n",
    "        self.phi_yaw_arr = []\n",
    "        self.EKF_yaw_arr = []\n",
    "        self.gc_yaw_arr = []\n",
    "\n",
    "        self.phi_pitch_arr = []\n",
    "        self.EKF_pitch_arr = []\n",
    "        self.gc_pitch_arr = []\n",
    "\n",
    "        self.time_arr = []\n",
    "    \n",
    "    def log(self, gc_angles, phi_yaw, EKF_yaw, phi_pitch, EKF_pitch, t):\n",
    "        self.phi_yaw_arr.append(phi_yaw)\n",
    "        self.EKF_yaw_arr.append(EKF_yaw.get_pos())\n",
    "\n",
    "        self.phi_pitch_arr.append(phi_pitch)\n",
    "        self.EKF_pitch_arr.append(EKF_pitch.get_pos())\n",
    "\n",
    "        self.gc_yaw_arr.append(gc_angles['yaw'])\n",
    "        self.gc_pitch_arr.append(gc_angles['pitch'])\n",
    "\n",
    "        self.time_arr.append(t)\n",
    "    \n",
    "    def plot(self):\n",
    "        plt.subplot(211)\n",
    "        plt.plot(self.time_arr, self.EKF_yaw_arr, label='EKF estimate of yaw [deg]')\n",
    "        plt.plot(self.time_arr, self.phi_yaw_arr, label='Raw NN estimate of yaw [deg]')\n",
    "        plt.plot(self.time_arr, self.gc_yaw_arr, label='Gimbal yaw [deg]')\n",
    "        plot_util(plt)\n",
    "\n",
    "        plt.subplot(212)\n",
    "        plt.plot(self.time_arr, self.EKF_pitch_arr, label='EKF estimate of pitch [deg]')\n",
    "        plt.plot(self.time_arr, self.phi_pitch_arr, label='Raw NN estimate of pitch [deg]')\n",
    "        plt.plot(self.time_arr, self.gc_pitch_arr, label='Gimbal pitch [deg]')\n",
    "        plot_util(plt)\n",
    "\n",
    "        loop_times_ms = [(t-t_)*1e3 for t_,t in zip(self.time_arr[0:-1], self.time_arr[1:])]\n",
    "        plt.stem(self.time_arr[:-1], loop_times_ms, label='loop times [ms]')\n",
    "        plot_util(plt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rolling buffer for gimbal angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GimbalAngleBuffer():\n",
    "    \"\"\" Keeps a rolling buffer of the last `buffer_len` angle readings from the gimbal,\n",
    "        including the time at which the angle readings were taken.\n",
    "        \n",
    "        If given the time at which a photo was taken, it returns the gimbal angle log\n",
    "        which was taken close to that time. \"\"\"\n",
    "    def __init__(self, buffer_len=20):\n",
    "        self.buffer_len = buffer_len\n",
    "        self.time_buffer = np.zeros(buffer_len)\n",
    "        self.yaw_buffer = np.zeros(buffer_len)\n",
    "        self.pitch_buffer = np.zeros(buffer_len)\n",
    "        self.idx = 0\n",
    "    \n",
    "    def log(self, gc_angles): # gc_angles is the dict returned from gc.get_motor_angles()\n",
    "        self.time_buffer[self.idx % self.buffer_len] = time.time()\n",
    "        self.yaw_buffer[self.idx % self.buffer_len] = gc_angles['yaw']\n",
    "        self.pitch_buffer[self.idx % self.buffer_len] = gc_angles['pitch']\n",
    "        self.idx += 1\n",
    "\n",
    "    def angle_closest_to(self, photo_time):\n",
    "        idx = np.argmin(np.abs(self.time_buffer - photo_time)) # time closest to the photo time\n",
    "        return self.yaw_buffer[idx], self.pitch_buffer[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__': # test/understand the rolling buffer\n",
    "    import time\n",
    "\n",
    "    x = GimbalAngleBuffer(4)\n",
    "\n",
    "    gc_angles1 = {'yaw': 20, 'pitch': 15}\n",
    "    gc_angles2 = {'yaw': 30, 'pitch': 25}\n",
    "    gc_angles3 = {'yaw': 40, 'pitch': 35}\n",
    "    gc_angles4 = {'yaw': 50, 'pitch': 45}\n",
    "\n",
    "    x.log(gc_angles1)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    x.log(gc_angles2)\n",
    "    time.sleep(0.2)\n",
    "    photo_time = time.time()\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    x.log(gc_angles3)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    x.log(gc_angles4)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    print(x.angle_closest_to(photo_time)) # should be (30, 25), as it corresponds to the angle nearest to the photo_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
